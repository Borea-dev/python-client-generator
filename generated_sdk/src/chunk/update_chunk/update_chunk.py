# generated by borea

# if you want to edit this file, add it to ignores in borea.config.json, glob syntax

# TODO: not implemented

from typing import Any, Dict, List, Optional, Union, TYPE_CHECKING
from ....models.models import *

if TYPE_CHECKING:
    from ...trieve_api import TrieveApi


class UpdateChunk:
    def __init__(self, parent: "TrieveApi"):
        self.parent = parent

    def update_chunk(
        self,
        tr_dataset: str,
        chunk_html: Optional[str] = None,
        chunk_id: Optional[str] = None,
        convert_html_to_text: Optional[bool] = None,
        fulltext_boost: Optional[FullTextBoost] = None,
        group_ids: Optional[List[str]] = None,
        group_tracking_ids: Optional[List[str]] = None,
        image_urls: Optional[List[str]] = None,
        link: Optional[str] = None,
        location: Optional[GeoInfo] = None,
        metadata: Optional[Any] = None,
        num_value: Optional[float] = None,
        semantic_boost: Optional[SemanticBoost] = None,
        tag_set: Optional[List[str]] = None,
        time_stamp: Optional[str] = None,
        tracking_id: Optional[str] = None,
        weight: Optional[float] = None,
    ) -> Any:
        """
        Update a chunk. If you try to change the tracking_id of the chunk to have the same tracking_id as an existing chunk, the request will fail. Auth'ed user or api key must have an admin or owner role for the specified dataset's organization.

        Args:
            tr_dataset: The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
            chunk_html: HTML content of the chunk you want to update. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content. If no chunk_html is provided, the existing chunk_html will be used.
            chunk_id: Id of the chunk you want to update. You can provide either the chunk_id or the tracking_id. If both are provided, the chunk_id will be used.
            convert_html_to_text: Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
            fulltext_boost: Boost the presence of certain tokens for fulltext (SPLADE) and keyword (BM25) search. I.e. boosting title phrases to priortize title matches or making sure that the listing for AirBNB itself ranks higher than companies who make software for AirBNB hosts by boosting the in-document-frequency of the AirBNB token (AKA word) for its official listing. Conceptually it multiples the in-document-importance second value in the tuples of the SPLADE or BM25 sparse vector of the chunk_html innerText for all tokens present in the boost phrase by the boost factor like so: (token, in-document-importance) -> (token, in-document-importance*boost_factor).
            group_ids: Group ids are the ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
            group_tracking_ids: Group tracking_ids are the tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
            image_urls: Image urls are a list of urls to images that are associated with the chunk. This is useful for when you want to associate images with a chunk. If no image_urls are provided, the existing image_urls will be used.
            link: Link of the chunk you want to update. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation. If no link is provided, the existing link will be used.
            location: Location that you want to use as the center of the search.
            metadata: The metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. If no metadata is provided, the existing metadata will be used.
            num_value: Num value is an arbitrary numerical value that can be used to filter chunks. This is useful for when you want to filter chunks by numerical value. If no num_value is provided, the existing num_value will be used.
            semantic_boost: Semantic boosting moves the dense vector of the chunk in the direction of the distance phrase for semantic search. I.e. you can force a cluster by moving every chunk for a PDF closer to its title or push a chunk with a chunk_html of "iphone" 25% closer to the term "flagship" by using the distance phrase "flagship" and a distance factor of 0.25. Conceptually it's drawing a line (euclidean/L2 distance) between the vector for the innerText of the chunk_html and distance_phrase then moving the vector of the chunk_html distance_factor*L2Distance closer to or away from the distance_phrase point along the line between the two points.
            tag_set: Tag set is a list of tags. This can be used to filter chunks by tag. Unlike with metadata filtering, HNSW indices will exist for each tag such that there is not a performance hit for filtering on them. If no tag_set is provided, the existing tag_set will be used.
            time_stamp: Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results. If no time_stamp is provided, the existing time_stamp will be used.
            tracking_id: Tracking_id of the chunk you want to update. This is required to match an existing chunk.
            weight: Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset. If no weight is provided, the existing weight will be used.

        Returns:
            Response data
        """
        path = f"/api/chunk"
        params = {}
        headers = {}
        if tr_dataset is not None:
            headers["TR-Dataset"] = tr_dataset
        json_data = {
            "chunk_html": chunk_html if chunk_html is not None else None,
            "chunk_id": chunk_id if chunk_id is not None else None,
            "convert_html_to_text": (
                convert_html_to_text if convert_html_to_text is not None else None
            ),
            "fulltext_boost": fulltext_boost if fulltext_boost is not None else None,
            "group_ids": group_ids if group_ids is not None else None,
            "group_tracking_ids": (
                group_tracking_ids if group_tracking_ids is not None else None
            ),
            "image_urls": image_urls if image_urls is not None else None,
            "link": link if link is not None else None,
            "location": location if location is not None else None,
            "metadata": metadata if metadata is not None else None,
            "num_value": num_value if num_value is not None else None,
            "semantic_boost": semantic_boost if semantic_boost is not None else None,
            "tag_set": tag_set if tag_set is not None else None,
            "time_stamp": time_stamp if time_stamp is not None else None,
            "tracking_id": tracking_id if tracking_id is not None else None,
            "weight": weight if weight is not None else None,
        }
        json_data = {k: v for k, v in json_data.items() if v is not None}

        response = self.parent._make_request(
            method="PUT",
            path=path,
            params=params,
            headers=headers,
            json_data=json_data,
        )
        return response.json()
