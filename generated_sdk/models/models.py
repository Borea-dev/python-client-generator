# generated by datamodel-codegen:
#   filename:  openapi.json

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Literal, Optional, Union
from uuid import UUID

from pydantic import BaseModel, Field, RootModel
from typing_extensions import Annotated


class APIVersion(Enum):
    V1 = "V1"
    V2 = "V2"


class AddChunkToGroupReqPayload(BaseModel):
    chunk_id: Optional[UUID] = None
    """
    Id of the chunk to make a member of the group.
    """
    chunk_tracking_id: Optional[str] = None
    """
    Tracking Id of the chunk to make a member of the group.
    """


class ApiKeyRespBody(BaseModel):
    created_at: datetime
    dataset_ids: Optional[list[str]] = None
    id: UUID
    name: str
    organization_id: UUID
    organization_ids: Optional[list[str]] = None
    role: int
    updated_at: datetime


class AuthQuery(BaseModel):
    inv_code: Optional[UUID] = None
    """
    Code sent via email as a result of successful call to send_invitation
    """
    organization_id: Optional[UUID] = None
    """
    ID of organization to authenticate into
    """
    redirect_uri: Optional[str] = None
    """
    URL to redirect to after successful login
    """


class ButtonTrigger(BaseModel):
    mode: str
    removeTriggers: Optional[bool] = None
    selector: str


class CTRType(Enum):
    search = "search"
    rag = "rag"
    recommendation = "recommendation"


class ChunkGroup(BaseModel):
    created_at: datetime
    dataset_id: UUID
    description: str
    id: UUID
    metadata: Optional[Any] = None
    name: str
    tag_set: Optional[list[Optional[str]]] = None
    tracking_id: Optional[str] = None
    updated_at: datetime


class ChunkGroupAndFileId(BaseModel):
    created_at: datetime
    dataset_id: UUID
    description: str
    file_id: Optional[UUID] = None
    id: UUID
    metadata: Optional[Any] = None
    name: str
    tag_set: Optional[list[Optional[str]]] = None
    tracking_id: Optional[str] = None
    updated_at: datetime


class ChunkGroups(RootModel[list[ChunkGroup]]):
    root: Annotated[
        list[ChunkGroup],
        Field(
            examples=[
                [
                    {
                        "created_at": "2021-01-01 00:00:00.000",
                        "dataset_id": "e3e3e3e3-e3e3-e3e3-e3e3-e3e3e3e3e3e3",
                        "description": (
                            "All versions and colorways of the oversized t-shirt"
                        ),
                        "metadata": {"foo": "bar"},
                        "name": "Versions of Oversized T-Shirt",
                        "tag_set": ["tshirt", "oversized", "clothing"],
                        "tracking_id": "SNOVERSIZEDTSHIRT",
                        "updated_at": "2021-01-01 00:00:00.000",
                    },
                    {
                        "created_at": "2021-01-01 00:00:00.000",
                        "dataset_id": "e3e3e3e3-e3e3-e3e3-e3e3-e3e3e3e3e3e3",
                        "description": (
                            "All versions and colorways of the slim-fit t-shirt"
                        ),
                        "metadata": {"foo": "bar"},
                        "name": "Versions of Slim-Fit T-Shirt",
                        "tag_set": ["tshirt", "slim", "clothing"],
                        "tracking_id": "SNSLIMFITTSHIRT",
                        "updated_at": "2021-01-01 00:00:00.000",
                    },
                ]
            ]
        ),
    ]


class ChunkHtmlContentReqPayload(BaseModel):
    body_remove_strings: Optional[list[str]] = None
    """
    Text strings to remove from body when creating chunks for each page
    """
    chunk_html: str
    """
    The HTML content to be split into chunks
    """
    heading_remove_strings: Optional[list[str]] = None
    """
    Text strings to remove from headings when creating chunks for each page
    """


class ChunkMetadataWithScore(BaseModel):
    chunk_html: Optional[str] = None
    created_at: datetime
    dataset_id: UUID
    id: UUID
    link: Optional[str] = None
    metadata: Optional[Any] = None
    score: float
    tag_set: Optional[str] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    updated_at: datetime
    weight: float


class ChunkReqPayloadFields(Enum):
    """
    The key in the ChunkReqPayload which you can map a column or field from the CSV or JSONL file to.
    """

    link = "link"
    tag_set = "tag_set"
    num_value = "num_value"
    tracking_id = "tracking_id"
    group_tracking_ids = "group_tracking_ids"
    time_stamp = "time_stamp"
    lat = "lat"
    lon = "lon"
    image_urls = "image_urls"
    weight = "weight"
    boost_phrase = "boost_phrase"


class ChunkReqPayloadMapping(BaseModel):
    """
    Express a mapping between a column or field in a CSV or JSONL field and a key in the ChunkReqPayload created for each row or object.
    """

    chunk_req_payload_field: ChunkReqPayloadFields
    csv_jsonl_field: str
    """
    The column or field in the CSV or JSONL file that you want to map to a key in the ChunkReqPayload
    """


class ChunkReqPayloadMappings(RootModel[list[ChunkReqPayloadMapping]]):
    """
    Specify all of the mappings between columns or fields in a CSV or JSONL file and keys in the ChunkReqPayload. Array fields like tag_set, image_urls, and group_tracking_ids can have multiple mappings. Boost phrase can also have multiple mappings which get concatenated. Other fields can only have one mapping and only the last mapping will be used.
    """

    root: list[ChunkReqPayloadMapping]
    """
    Specify all of the mappings between columns or fields in a CSV or JSONL file and keys in the ChunkReqPayload. Array fields like tag_set, image_urls, and group_tracking_ids can have multiple mappings. Boost phrase can also have multiple mappings which get concatenated. Other fields can only have one mapping and only the last mapping will be used.
    """


class ChunkWithPosition(BaseModel):
    chunk_id: UUID
    position: int


class ChunkedContent(BaseModel):
    body: str
    """
    The body of the content
    """
    headings: list[str]
    """
    The headings of the content in order of when they appear
    """


class ClickhouseRagTypes(Enum):
    chosen_chunks = "chosen_chunks"
    all_chunks = "all_chunks"


class ClickhouseRecommendationTypes(Enum):
    Chunk = "Chunk"
    Group = "Group"


class ClickhouseSearchTypes(Enum):
    search = "search"
    search_over_groups = "search_over_groups"
    autocomplete = "autocomplete"
    rag = "rag"


class CloneTopicReqPayload(BaseModel):
    name: Optional[str] = None
    """
    The name of the topic. If this is not provided, the topic name is the same as the previous topic
    """
    owner_id: str
    """
    The owner_id of the topic. This is typically a browser fingerprint or your user's id. It is used to group topics together for a user.
    """
    topic_id: UUID
    """
    The topic_id to clone from
    """


class ClusterAnalytics2(BaseModel):
    cluster_id: UUID
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]


class ContentChunkMetadata(BaseModel):
    chunk_html: Optional[str] = None
    id: UUID
    image_urls: Optional[list[Optional[str]]] = None
    num_value: Optional[float] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    weight: float


class ContextOptions(BaseModel):
    """
    Context options to use for the completion. If not specified, all options will default to false.
    """

    include_links: Optional[bool] = None
    """
    Include links in the context. If not specified, this defaults to false.
    """


class CountChunkQueryResponseBody(BaseModel):
    count: Annotated[int, Field(ge=0)]


class CountSearchMethod(Enum):
    fulltext = "fulltext"
    semantic = "semantic"
    bm25 = "bm25"


class CrawlInterval(Enum):
    """
    Interval at which specified site should be re-scraped
    """

    daily = "daily"
    weekly = "weekly"
    monthly = "monthly"


class CrawlOpenAPIOptions(BaseModel):
    """
    Options for including an openapi spec in the crawl
    """

    openapi_schema_url: str
    """
    OpenAPI json schema to be processed alongside the site crawl
    """
    openapi_tag: str
    """
    Tag to look for to determine if a page should create an openapi route chunk instead of chunks from heading-split of the HTML
    """


class CrawlShopifyOptions(BaseModel):
    """
    Options for Crawling Shopify
    """

    group_variants: Optional[bool] = None
    """
    This option will ingest all variants as individual chunks and place them in groups by product id. Turning this off will only scrape 1 variant per product. default: true
    """
    tag_regexes: Optional[list[str]] = None


class CrawlStatus1(BaseModel):
    Processing: Annotated[int, Field(ge=0)]


class CrawlStatus(
    RootModel[
        Union[Literal["Pending"], CrawlStatus1, Literal["Completed"], Literal["Failed"]]
    ]
):
    root: Union[
        Literal["Pending"], CrawlStatus1, Literal["Completed"], Literal["Failed"]
    ]


class CrawlType(Enum):
    firecrawl = "firecrawl"
    openapi = "openapi"
    shopify = "shopify"
    youtube = "youtube"


class CrawlYoutubeOptions(BaseModel):
    """
    Options for Crawling Youtube
    """


class CreateApiKeyResponse(BaseModel):
    api_key: str
    """
    The api key which was created. This is the value which should be used in the Authorization header.
    """


class CreateChunkGroupResponseEnum(RootModel[Union[ChunkGroup, ChunkGroups]]):
    root: Union[ChunkGroup, ChunkGroups]


class CreateOrganizationReqPayload(BaseModel):
    name: str
    """
    The arbitrary name which will be used to identify the organization. This name must be unique.
    """


class CreatePresignedUrlForCsvJsonlReqPayload(BaseModel):
    description: Optional[str] = None
    """
    Description is an optional convience field so you do not have to remember what the file contains or is about. It will be included on the group resulting from the file which will hold its chunk.
    """
    file_name: str
    """
    Name of the file being uploaded, including the extension. Will be used to determine CSV or JSONL for processing.
    """
    fulltext_boost_factor: Optional[float] = None
    """
    Amount to multiplicatevly increase the frequency of the tokens in the boost phrase for each row's chunk by. Applies to fulltext (SPLADE) and keyword (BM25) search.
    """
    group_tracking_id: Optional[str] = None
    """
    Group tracking id is an optional field which allows you to specify the tracking id of the group that is created from the file. Chunks created will be created with the tracking id of `group_tracking_id|<index of chunk>`
    """
    link: Optional[str] = None
    """
    Link to the file. This can also be any string. This can be used to filter when searching for the file's resulting chunks. The link value will not affect embedding creation.
    """
    mappings: Optional[ChunkReqPayloadMappings] = None
    metadata: Optional[Any] = None
    """
    Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. Will be passed down to the file's chunks.
    """
    semantic_boost_factor: Optional[float] = None
    """
    Arbitrary float (positive or negative) specifying the multiplicate factor to apply before summing the phrase vector with the chunk_html embedding vector. Applies to semantic (embedding model) search.
    """
    tag_set: Optional[list[str]] = None
    """
    Tag set is a comma separated list of tags which will be passed down to the chunks made from the file. Each tag will be joined with what's creatd per row of the CSV or JSONL file.
    """
    time_stamp: Optional[str] = None
    """
    Time stamp should be an ISO 8601 combined date and time without timezone. Time_stamp is used for time window filtering and recency-biasing search results. Will be passed down to the file's chunks.
    """
    upsert_by_tracking_id: Optional[bool] = None
    """
    Upsert by tracking_id. If true, chunks will be upserted by tracking_id. If false, chunks with the same tracking_id as another already existing chunk will be ignored. Defaults to true.
    """


class CreateSchemaReqPayload(BaseModel):
    include_images: Optional[bool] = None
    model: Optional[str] = None
    prompt: str
    tag_enum: Optional[list[str]] = None


class CreateSetupCheckoutSessionResPayload(BaseModel):
    url: str


class CreateSingleChunkGroupReqPayload(BaseModel):
    description: Optional[str] = None
    """
    Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for.
    """
    metadata: Optional[Any] = None
    """
    Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
    """
    name: Optional[str] = None
    """
    Name to assign to the chunk_group. Does not need to be unique.
    """
    tag_set: Optional[list[str]] = None
    """
    Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
    """
    tracking_id: Optional[str] = None
    """
    Optional tracking id to assign to the chunk_group. This is a unique identifier for the chunk_group.
    """
    upsert_by_tracking_id: Optional[bool] = None
    """
    Upsert when a chunk_group with the same tracking_id exists. By default this is false, and the request will fail if a chunk_group with the same tracking_id exists. If this is true, the chunk_group will be updated if a chunk_group with the same tracking_id exists.
    """


class CreateTopicReqPayload(BaseModel):
    first_user_message: Optional[str] = None
    """
    The first message which will belong to the topic. The topic name is generated based on this message similar to how it works in the OpenAI chat UX if a name is not explicitly provided on the name request body key.
    """
    name: Optional[str] = None
    """
    The name of the topic. If this is not provided, the topic name is generated from the first_user_message.
    """
    owner_id: str
    """
    The owner_id of the topic. This is typically a browser fingerprint or your user's id. It is used to group topics together for a user.
    """


class Dataset(BaseModel):
    created_at: datetime
    """
    Timestamp of the creation of the dataset
    """
    deleted: int
    """
    Flag to indicate if the dataset has been deleted. Deletes are handled async after the flag is set so as to avoid expensive search index compaction.
    """
    id: UUID
    """
    Unique identifier of the dataset, auto-generated uuid created by Trieve
    """
    name: str
    """
    Name of the dataset
    """
    organization_id: UUID
    """
    Unique identifier of the organization that owns the dataset
    """
    server_configuration: Any
    """
    Configuration of the dataset for RAG, embeddings, BM25, etc.
    """
    tracking_id: Optional[str] = None
    """
    Tracking ID of the dataset, can be any string, determined by the user. Tracking ID's are unique identifiers for datasets within an organization. They are designed to match the unique identifier of the dataset in the user's system.
    """
    updated_at: datetime
    """
    Timestamp of the last update of the dataset
    """


class DatasetAnalytics(BaseModel):
    avg_latency: float
    p50: float
    p95: float
    p99: float
    search_rps: float
    total_queries: int


class DatasetDTO(BaseModel):
    created_at: datetime
    id: UUID
    name: str
    organization_id: UUID
    tracking_id: Optional[str] = None
    updated_at: datetime


class DatasetUsageCount(BaseModel):
    chunk_count: int
    dataset_id: UUID
    id: UUID


class Datasets(RootModel[list[Dataset]]):
    """
    Datasets
    """

    root: list[Dataset]
    """
    Datasets
    """


class DateRange(BaseModel):
    """
    DateRange is a JSON object which can be used to filter chunks by a range of dates. This leverages the time_stamp field on chunks in your dataset. You can specify this if you want values in a certain range. You must provide ISO 8601 combined date and time without timezone.
    """

    gt: Optional[str] = None
    gte: Optional[str] = None
    lt: Optional[str] = None
    lte: Optional[str] = None


class DeleteTopicData(BaseModel):
    topic_id: UUID
    """
    The id of the topic to target.
    """


class DistanceMetric(Enum):
    euclidean = "euclidean"
    cosine = "cosine"
    manhattan = "manhattan"
    dot = "dot"


class ErrorResponseBody(BaseModel):
    message: str


class EventData(BaseModel):
    """
    EventData represents a single analytics event
    """

    created_at: str
    """
    The time the event was created.
    """
    dataset_id: UUID
    """
    The unique identifier for the dataset the event is associated with.
    """
    event_name: str
    """
    The name of the event, e.g. "Added to Cart", "Purchased", "Viewed Home Page", "Clicked", "Filter Clicked".
    """
    event_type: str
    """
    The type of event, "add_to_cart", "purchase", "view", "click", "filter_clicked".
    """
    id: UUID
    """
    The unique identifier for the event
    """
    is_conversion: Optional[bool] = None
    """
    Whether the event is a conversion event.
    """
    items: list[str]
    """
    The items associated with the event. This could be a list of stringified json chunks for search events, or a list of items for add_to_cart, purchase, view, and click events.
    """
    metadata: Optional[Any] = None
    """
    Additional metadata associated with the event. This can be custom data that is specific to the event.
    """
    request_id: Optional[str] = None
    """
    The unique identifier for the request the event is associated with.
    """
    request_type: Optional[str] = None
    """
    The type of request the event is associated with.
    """
    updated_at: str
    """
    The time the event was last updated.
    """
    user_id: Optional[str] = None
    """
    The user identifier associated with the event.
    """


class EventTypeRequest(Enum):
    file_uploaded = "file_uploaded"
    file_upload_failed = "file_upload_failed"
    chunks_uploaded = "chunks_uploaded"
    chunk_action_failed = "chunk_action_failed"
    chunk_updated = "chunk_updated"
    bulk_chunks_deleted = "bulk_chunks_deleted"
    chunk_update_failed = "chunk_update_failed"
    dataset_delete_failed = "dataset_delete_failed"
    qdrant_upload_failed = "qdrant_upload_failed"
    bulk_chunk_upload_failed = "bulk_chunk_upload_failed"
    group_chunks_updated = "group_chunks_updated"
    group_chunks_action_failed = "group_chunks_action_failed"
    crawl_completed = "crawl_completed"
    crawl_failed = "crawl_failed"
    crawl_started = "crawl_started"
    csv_jsonl_processing_failed = "csv_jsonl_processing_failed"
    csv_jsonl_processing_checkpoint = "csv_jsonl_processing_checkpoint"
    csv_jsonl_processing_completed = "csv_jsonl_processing_completed"
    video_uploaded = "video_uploaded"
    pagefind_indexing_started = "pagefind_indexing_started"
    pagefind_indexing_finished = "pagefind_indexing_finished"
    etl_started = "etl_started"
    etl_completed = "etl_completed"
    etl_failed = "etl_failed"


class EventTypes8(BaseModel):
    event_type: Literal["7#-datamodel-code-generator-#-object-#-special-#"]
    negative_ids: Optional[list[UUID]] = None
    """
    Negative ids used for the recommendation
    """
    negative_tracking_ids: Optional[list[str]] = None
    """
    Negative tracking ids used for the recommendation
    """
    positive_ids: Optional[list[UUID]] = None
    """
    Positive ids used for the recommendation
    """
    positive_tracking_ids: Optional[list[str]] = None
    """
    Positive tracking ids used for the recommendation
    """
    recommendation_type: Optional[ClickhouseRecommendationTypes] = None
    request_params: Optional[Any] = None
    """
    The request params of the recommendation
    """
    results: Optional[list] = None
    """
    The results of the Recommendation event
    """
    top_score: Optional[float] = None
    """
    Top score of the recommendation
    """
    user_id: Optional[str] = None
    """
    The user id of the user who made the recommendation
    """


class EventTypesFilter(Enum):
    add_to_cart = "add_to_cart"
    purchase = "purchase"
    view = "view"
    click = "click"
    filter_clicked = "filter_clicked"


class File(BaseModel):
    created_at: datetime
    dataset_id: UUID
    file_name: str
    id: UUID
    link: Optional[str] = None
    metadata: Optional[Any] = None
    size: int
    tag_set: Optional[list[Optional[str]]] = None
    time_stamp: Optional[datetime] = None
    updated_at: datetime


class FileAndGroupId(BaseModel):
    file: File
    group_id: Optional[UUID] = None


class FileDTO(BaseModel):
    created_at: datetime
    file_name: str
    id: UUID
    link: Optional[str] = None
    metadata: Optional[Any] = None
    s3_url: str
    size: int
    updated_at: datetime


class FileData(BaseModel):
    file_and_group_ids: list[FileAndGroupId]
    total_pages: int


class FullTextBoost(BaseModel):
    """
    Boost the presence of certain tokens for fulltext (SPLADE) and keyword (BM25) search. I.e. boosting title phrases to priortize title matches or making sure that the listing for AirBNB itself ranks higher than companies who make software for AirBNB hosts by boosting the in-document-frequency of the AirBNB token (AKA word) for its official listing. Conceptually it multiples the in-document-importance second value in the tuples of the SPLADE or BM25 sparse vector of the chunk_html innerText for all tokens present in the boost phrase by the boost factor like so: (token, in-document-importance) -> (token, in-document-importance*boost_factor).
    """

    boost_factor: float
    """
    Amount to multiplicatevly increase the frequency of the tokens in the phrase by
    """
    phrase: str
    """
    The phrase to boost in the fulltext document frequency index
    """


class GeoTypes(RootModel[Union[int, float]]):
    root: Union[int, float]


class GetAllTagsReqPayload(BaseModel):
    page: Optional[int] = None
    """
    Page number to return, 1-indexed. Default is 1.
    """
    page_size: Optional[int] = None
    """
    Number of items to return per page. Default is 20.
    """


class GetChunkGroupCountRequest(BaseModel):
    group_id: Optional[UUID] = None
    """
    The Id of the group to get the count for, is not required if group_tracking_id is provided.
    """
    group_tracking_id: Optional[str] = None
    """
    The tracking id of the group to get the count for, is not required if group_id is provided.
    """


class GetChunkGroupCountResponse(BaseModel):
    count: Annotated[int, Field(ge=0)]
    """
    The count of chunks in the given group.
    """
    group_id: UUID
    """
    The Id of the group to get the count for.
    """


class GetChunksData(BaseModel):
    ids: list[UUID]


class GetCrawlRequestsReqPayload(BaseModel):
    limit: Optional[int] = None
    page: Optional[int] = None


class GetDatasetsPagination(BaseModel):
    limit: Optional[int] = None
    offset: Optional[int] = None


class GetEventsData(BaseModel):
    event_types: Optional[list[EventTypeRequest]] = None
    """
    The types of events to get. Leave undefined to get all events.
    """
    page: Optional[int] = None
    """
    The page number to get. Default is 1.
    """
    page_size: Optional[int] = None
    """
    The number of items per page. Default is 10.
    """


class GetEventsResponseBody(BaseModel):
    """
    Response body for the GetEvents endpoint
    """

    events: list[EventData]


class GetGroupsForChunksReqPayload(BaseModel):
    chunk_ids: Optional[list[UUID]] = None
    chunk_tracking_ids: Optional[list[str]] = None


class GetPagefindIndexResponse(BaseModel):
    url: str


class GetToolFunctionParamsRespBody(BaseModel):
    """
    Response body for getting the parameters of a tool function
    """

    parameters: Optional[Any] = None
    """
    Parameters for the tool function.
    """


class GetTrackingChunksData(BaseModel):
    tracking_ids: list[str]


class Granularity(Enum):
    minute = "minute"
    second = "second"
    hour = "hour"
    day = "day"
    month = "month"


class GroupData(BaseModel):
    groups: list[ChunkGroupAndFileId]
    total_pages: Annotated[int, Field(ge=0)]


class GroupsForChunk(BaseModel):
    chunk_uuid: UUID
    slim_groups: list[ChunkGroupAndFileId]


class HasChunkIDCondition(BaseModel):
    """
    HasChunkIDCondition is a JSON object which can be used to filter chunks by their ids or tracking ids. This is useful for when you want to filter chunks by their ids or tracking ids.
    """

    ids: Optional[list[UUID]] = None
    """
    Ids of the chunks to apply a match_any condition with. Only chunks with one of these ids will be returned.
    """
    tracking_ids: Optional[list[str]] = None
    """
    Tracking ids of the chunks to apply a match_any condition with. Only chunks with one of these tracking ids will be returned.
    """


class HeadQueries(BaseModel):
    count: int
    query: str


class HeadQueryResponse(BaseModel):
    queries: list[HeadQueries]


class HeroPattern(BaseModel):
    backgroundColor: Optional[str] = None
    foregroundColor: Optional[str] = None
    foregroundOpacity: Optional[float] = None
    heroPatternName: Optional[str] = None
    heroPatternSvg: Optional[str] = None


class HighlightStrategy(Enum):
    exactmatch = "exactmatch"
    v1 = "v1"


class ImageConfig(BaseModel):
    """
    Configuration for sending images to the llm
    """

    images_per_chunk: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of Images to send to the llm per chunk that is fetched more images may slow down llm inference time. default: 5
    """
    use_images: Optional[bool] = None
    """
    This sends images to the llm if chunk_metadata.image_urls has some value, the call will error if the model is not a vision LLM model. default: false
    """


class Invitation(BaseModel):
    created_at: datetime
    email: str
    id: UUID
    organization_id: UUID
    role: int
    updated_at: datetime
    used: bool


class InvitationData(BaseModel):
    app_url: str
    """
    The url of the app that the user will be directed to in order to set their password. Usually admin.trieve.ai, but may differ for local dev or self-hosted setups.
    """
    email: str
    """
    The email of the user to invite. Must be a valid email as they will be sent an email to register.
    """
    redirect_uri: str
    """
    The url that the user will be redirected to after setting their password.
    """
    user_role: int
    """
    The role the user will have in the organization. 0 = User, 1 = Admin, 2 = Owner.
    """


class LLMOptions(BaseModel):
    """
    LLM options to use for the completion. If not specified, this defaults to the dataset's LLM options.
    """

    completion_first: Optional[bool] = None
    """
    Completion first decides whether the stream should contain the stream of the completion response or the chunks first. Default is false. Keep in mind that || is used to separate the chunks from the completion response. If || is in the completion then you may want to split on ||{ instead.
    """
    frequency_penalty: Optional[float] = None
    """
    Frequency penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. Default is 0.7.
    """
    image_config: Optional[ImageConfig] = None
    max_tokens: Annotated[Optional[int], Field(ge=0)] = None
    """
    The maximum number of tokens to generate in the chat completion. Default is None.
    """
    presence_penalty: Optional[float] = None
    """
    Presence penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Default is 0.7.
    """
    stop_tokens: Optional[list[str]] = None
    """
    Stop tokens are up to 4 sequences where the API will stop generating further tokens. Default is None.
    """
    stream_response: Optional[bool] = None
    """
    Whether or not to stream the response. If this is set to true or not included, the response will be a stream. If this is set to false, the response will be a normal JSON response. Default is true.
    """
    system_prompt: Optional[str] = None
    """
    Optionally, override the system prompt in dataset server settings.
    """
    temperature: Optional[float] = None
    """
    What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Default is 0.5.
    """


class MatchCondition(RootModel[Union[str, int, float]]):
    root: Union[str, int, float]


class Message(BaseModel):
    completion_tokens: Optional[int] = None
    content: str
    created_at: datetime
    dataset_id: UUID
    deleted: bool
    id: UUID
    prompt_tokens: Optional[int] = None
    role: str
    sort_order: int
    topic_id: UUID
    updated_at: datetime


class MmrOptions(BaseModel):
    """
    MMR Options lets you specify different methods to rerank the chunks in the result set using Maximal Marginal Relevance. If not specified, this defaults to the score of the chunks.
    """

    mmr_lambda: Optional[float] = None
    """
    Set mmr_lambda to a value between 0.0 and 1.0 to control the tradeoff between relevance and diversity. Closer to 1.0 will give more diverse results, closer to 0.0 will give more relevant results. If not specified, this defaults to 0.5.
    """
    use_mmr: bool
    """
    Set use_mmr to true to use the Maximal Marginal Relevance algorithm to rerank the results.
    """


class OpenGraphMetadata(BaseModel):
    description: Optional[str] = None
    image: Optional[str] = None
    title: Optional[str] = None


class Organization(BaseModel):
    created_at: datetime
    """
    Timestamp of the creation of the dataset
    """
    deleted: int
    """
    Flag to indicate if the organization has been deleted. Deletes are handled async after the flag is set so as to avoid expensive search index compaction.
    """
    id: UUID
    """
    Unique identifier of the dataset, auto-generated uuid created by Trieve
    """
    name: str
    """
    Name of the organization
    """
    partner_configuration: Any
    """
    Configuration of the organization for the Trieve partner program. Contact partnerships@trieve.ai for more details.
    """
    registerable: Optional[bool] = None
    """
    Flag to indicate whether or not new users may join the organization. Default is true.
    """
    updated_at: datetime
    """
    Timestamp of the last update of the dataset
    """


class OrganizationUsageCount(BaseModel):
    chunk_count: int
    dataset_count: int
    file_storage: int
    id: UUID
    message_count: int
    org_id: UUID
    user_count: int


class PartnerConfiguration(BaseModel):
    CALENDAR_LINK: str
    COMPANY_NAME: str
    COMPANY_URL: str
    DEMO_DOMAIN: str
    EMAIL: str
    FAVICON_URL: str
    LINKEDIN_LINK: str
    PHONE: str
    SLACK_LINK: str


class Pdf2MdOptions(BaseModel):
    split_headings: Optional[bool] = None
    """
    Split headings is an optional field which allows you to specify whether or not to split headings into separate chunks. Default is false.
    """
    system_prompt: Optional[str] = None
    """
    Prompt to use for the gpt-4o model. Default is None.
    """
    use_pdf2md_ocr: bool
    """
    Parameter to use pdf2md_ocr. If true, the file will be converted to markdown using gpt-4o. Default is false.
    """


class PopularFilters(BaseModel):
    clause: str
    common_values: dict[str, int]
    count: int
    field: str
    filter_type: str


class PopularFiltersResponse(BaseModel):
    popular_filters: list[PopularFilters]


class PublicPageTabMessage(BaseModel):
    showComponentCode: bool
    tabInnerHtml: str
    title: str


class PublicPageTag(BaseModel):
    description: Optional[str] = None
    iconClassName: Optional[str] = None
    label: Optional[str] = None
    selected: Optional[bool] = None
    tag: str


class PublicPageTheme(Enum):
    light = "light"
    dark = "dark"


class RAGAnalytics4(BaseModel):
    request_id: UUID
    type: Literal["3#-datamodel-code-generator-#-object-#-special-#"]


class RAGSortBy(Enum):
    hallucination_score = "hallucination_score"
    top_score = "top_score"
    created_at = "created_at"
    latency = "latency"


class RAGUsageResponse(BaseModel):
    total_queries: Annotated[int, Field(ge=0)]


class RagTypes(Enum):
    chosen_chunks = "chosen_chunks"
    all_chunks = "all_chunks"


class RangeCondition(RootModel[Union[float, int]]):
    root: Union[float, int]


class RateQueryRequest(BaseModel):
    note: Optional[str] = None
    query_id: UUID
    rating: int


class ReRankOptions(Enum):
    semantic = "semantic"
    fulltext = "fulltext"
    bm25 = "bm25"
    cross_encoder = "cross_encoder"


class RecommendType(Enum):
    """
    The type of recommendation to make. This lets you choose whether to recommend based off of `semantic` or `fulltext` similarity. The default is `semantic`.
    """

    semantic = "semantic"
    fulltext = "fulltext"
    bm25 = "bm25"


class RecommendationAnalytics3(BaseModel):
    request_id: UUID
    type: Literal["2#-datamodel-code-generator-#-object-#-special-#"]


class RecommendationCTRMetrics(BaseModel):
    avg_position_of_click: float
    percent_recommendations_with_clicks: float
    percent_recommendations_without_clicks: float
    recommendations_with_clicks: int


class RecommendationEvent(BaseModel):
    created_at: str
    dataset_id: UUID
    id: UUID
    negative_ids: list[UUID]
    negative_tracking_ids: list[str]
    positive_ids: list[UUID]
    positive_tracking_ids: list[str]
    recommendation_type: ClickhouseRecommendationTypes
    request_params: Any
    results: list
    top_score: float
    user_id: str


class RecommendationStrategy(Enum):
    """
    Strategy to use for recommendations, either "average_vector" or "best_score". The default is "average_vector". The "average_vector" strategy will construct a single average vector from the positive and negative samples then use it to perform a pseudo-search. The "best_score" strategy is more advanced and navigates the HNSW with a heuristic of picking edges where the point is closer to the positive samples than it is the negatives.
    """

    average_vector = "average_vector"
    best_score = "best_score"


class RecommendationType(Enum):
    Chunk = "Chunk"
    Group = "Group"


class RecommendationsEventResponse(BaseModel):
    queries: list[RecommendationEvent]


class RecommendationsWithoutClicksCTRResponse(BaseModel):
    created_at: str
    negative_ids: Optional[list[str]] = None
    negative_tracking_ids: Optional[list[str]] = None
    positive_ids: Optional[list[str]] = None
    positive_tracking_ids: Optional[list[str]] = None
    request_id: str


class RemoveChunkFromGroupReqPayload(BaseModel):
    chunk_id: UUID
    """
    Id of the chunk to remove from the group.
    """


class RequestInfo(BaseModel):
    request_id: UUID
    request_type: CTRType


class RoleProxy(Enum):
    system = "system"
    user = "user"
    assistant = "assistant"


class ScrapeOptions1(CrawlOpenAPIOptions):
    """
    Options for including an openapi spec or shopify settigns
    """

    type: Literal["0#-datamodel-code-generator-#-allOf-#-special-#"]


class ScrapeOptions2(CrawlShopifyOptions):
    """
    Options for including an openapi spec or shopify settigns
    """

    type: Literal["1#-datamodel-code-generator-#-allOf-#-special-#"]


class ScrapeOptions3(CrawlYoutubeOptions):
    """
    Options for including an openapi spec or shopify settigns
    """

    type: Literal["2#-datamodel-code-generator-#-allOf-#-special-#"]


class ScrapeOptions(RootModel[Union[ScrapeOptions1, ScrapeOptions2, ScrapeOptions3]]):
    root: Annotated[
        Union[ScrapeOptions1, ScrapeOptions2, ScrapeOptions3],
        Field(discriminator="type"),
    ]
    """
    Options for including an openapi spec or shopify settigns
    """


class SearchAnalytics9(BaseModel):
    request_id: UUID
    type: Literal["8#-datamodel-code-generator-#-object-#-special-#"]


class SearchCTRMetrics(BaseModel):
    avg_position_of_click: float
    percent_searches_with_clicks: float
    percent_searches_without_clicks: float
    searches_with_clicks: int


class SearchClusterTopics(BaseModel):
    avg_score: float
    created_at: str
    dataset_id: UUID
    density: int
    id: UUID
    topic: str


class SearchLatencyGraph(BaseModel):
    average_latency: float
    time_stamp: str


class SearchMethod(Enum):
    fulltext = "fulltext"
    semantic = "semantic"
    hybrid = "hybrid"
    bm25 = "bm25"


class SearchModalities1(BaseModel):
    image_url: str
    llm_prompt: Optional[str] = None


class SearchModalities2(BaseModel):
    audio_base64: str


class SearchModalities(RootModel[Union[SearchModalities1, str, SearchModalities2]]):
    root: Union[SearchModalities1, str, SearchModalities2]


class SearchQueriesWithoutClicksCTRResponse(BaseModel):
    created_at: str
    query: str
    request_id: str


class SearchQueryRating(BaseModel):
    note: Optional[str] = None
    rating: int


class SearchSortBy(Enum):
    created_at = "created_at"
    latency = "latency"
    top_score = "top_score"


class SearchType(Enum):
    search = "search"
    autocomplete = "autocomplete"
    search_over_groups = "search_over_groups"
    search_within_groups = "search_within_groups"


class SearchTypeCount(BaseModel):
    search_count: int
    search_method: str
    search_type: str


class SemanticBoost(BaseModel):
    """
    Semantic boosting moves the dense vector of the chunk in the direction of the distance phrase for semantic search. I.e. you can force a cluster by moving every chunk for a PDF closer to its title or push a chunk with a chunk_html of "iphone" 25% closer to the term "flagship" by using the distance phrase "flagship" and a distance factor of 0.25. Conceptually it's drawing a line (euclidean/L2 distance) between the vector for the innerText of the chunk_html and distance_phrase then moving the vector of the chunk_html distance_factor*L2Distance closer to or away from the distance_phrase point along the line between the two points.
    """

    distance_factor: float
    """
    Arbitrary float (positive or negative) specifying the multiplicate factor to apply before summing the phrase vector with the chunk_html embedding vector
    """
    phrase: str
    """
    Terms to embed in order to create the vector which is weighted summed with the chunk_html embedding vector
    """


class SingleProductOptions(BaseModel):
    groupTrackingId: Optional[str] = None
    productDescriptionHtml: Optional[str] = None
    productName: Optional[str] = None
    productPrimaryImageUrl: Optional[str] = None
    productQuestions: Optional[list[str]] = None
    productTrackingId: Optional[str] = None
    recSearchQuery: Optional[str] = None


class Sitemap(BaseModel):
    changefreq: str


class SlimChunkMetadataWithScore(BaseModel):
    created_at: datetime
    id: UUID
    link: Optional[str] = None
    metadata: Optional[Any] = None
    score: float
    tag_set: Optional[str] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    updated_at: datetime
    weight: float


class SortBySearchType(BaseModel):
    prefetch_amount: Annotated[Optional[int], Field(ge=0)] = None
    """
    How many results to pull in before the rerabj
    """
    rerank_query: Optional[str] = None
    """
    Query to use for prefetching defaults to the search query
    """
    rerank_type: ReRankOptions


class SortOrder(Enum):
    desc = "desc"
    asc = "asc"


class SplitHtmlResponse(BaseModel):
    chunks: list[ChunkedContent]


class StripeInvoice(BaseModel):
    created_at: datetime
    hosted_invoice_url: str
    id: UUID
    org_id: UUID
    status: str
    stripe_id: Optional[str] = None
    total: int


class StripePlan(BaseModel):
    amount: int
    chunk_count: int
    created_at: datetime
    dataset_count: int
    file_storage: int
    id: UUID
    message_count: int
    name: str
    stripe_id: str
    updated_at: datetime
    user_count: int
    visible: bool


class StripeSubscription(BaseModel):
    created_at: datetime
    current_period_end: Optional[datetime] = None
    id: UUID
    organization_id: UUID
    plan_id: UUID
    stripe_id: str
    updated_at: datetime


class SuggestType(Enum):
    question = "question"
    keyword = "keyword"
    semantic = "semantic"


class SuggestedQueriesResponse(BaseModel):
    queries: list[str]


class TagsWithCount(BaseModel):
    count: int
    """
    Number of chunks in the dataset with that tag
    """
    tag: str
    """
    Content of the tag
    """


class ToolFunctionParameterType(Enum):
    """
    Type of a given parameter for a LLM tool call
    """

    number = "number"
    boolean = "boolean"


class TopDatasetsRequestTypes(Enum):
    search = "search"
    rag = "rag"
    recommendation = "recommendation"


class TopDatasetsResponse(BaseModel):
    dataset_id: UUID
    dataset_tracking_id: Optional[str] = None
    total_queries: int


class Topic(BaseModel):
    created_at: datetime
    dataset_id: UUID
    deleted: bool
    id: UUID
    name: str
    owner_id: str
    updated_at: datetime


class TypoRange(BaseModel):
    """
    The TypoRange struct is used to specify the range of which the query will be corrected if it has a typo.
    """

    max: Annotated[Optional[int], Field(ge=0)] = None
    """
    The maximum number of characters that the query will be corrected if it has a typo. If not specified, this defaults to 8.
    """
    min: Annotated[int, Field(ge=0)]
    """
    The minimum number of characters that the query will be corrected if it has a typo. If not specified, this defaults to 5.
    """


class UpdateAllOrgDatasetConfigsReqPayload(BaseModel):
    dataset_config: Any
    """
    The new configuration for all datasets in the organization. Only the specified keys in the configuration object will be changed per dataset such that you can preserve dataset unique values.
    """


class UpdateChunkByTrackingIdData(BaseModel):
    chunk_html: Optional[str] = None
    """
    HTML content of the chunk you want to update. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content. If no chunk_html is provided, the existing chunk_html will be used.
    """
    convert_html_to_text: Optional[bool] = None
    """
    Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
    """
    group_ids: Optional[list[UUID]] = None
    """
    Group ids are the ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
    """
    group_tracking_ids: Optional[list[str]] = None
    """
    Group tracking_ids are the tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
    """
    link: Optional[str] = None
    """
    Link of the chunk you want to update. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation. If no link is provided, the existing link will be used.
    """
    metadata: Optional[Any] = None
    """
    The metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. If no metadata is provided, the existing metadata will be used.
    """
    time_stamp: Optional[str] = None
    """
    Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results. If no time_stamp is provided, the existing time_stamp will be used.
    """
    tracking_id: str
    """
    Tracking_id of the chunk you want to update. This is required to match an existing chunk.
    """
    weight: Optional[float] = None
    """
    Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset. If no weight is provided, the existing weight will be used.
    """


class UpdateChunkGroupReqPayload(BaseModel):
    description: Optional[str] = None
    """
    Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for. If not provided, the description will not be updated.
    """
    group_id: Optional[UUID] = None
    """
    Id of the chunk_group to update.
    """
    metadata: Optional[Any] = None
    """
    Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
    """
    name: Optional[str] = None
    """
    Name to assign to the chunk_group. Does not need to be unique. If not provided, the name will not be updated.
    """
    tag_set: Optional[list[str]] = None
    """
    Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
    """
    tracking_id: Optional[str] = None
    """
    Tracking Id of the chunk_group to update.
    """
    update_chunks: Optional[bool] = None
    """
    Flag to update the chunks in the group. If true, each chunk in the group will be updated
    by appending the group's tags to the chunk's tags. Default is false.
    """


class UpdateGroupByTrackingIDReqPayload(BaseModel):
    description: Optional[str] = None
    """
    Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for. If not provided, the description will not be updated.
    """
    metadata: Optional[Any] = None
    """
    Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
    """
    name: Optional[str] = None
    """
    Name to assign to the chunk_group. Does not need to be unique. If not provided, the name will not be updated.
    """
    tag_set: Optional[list[str]] = None
    """
    Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
    """
    tracking_id: str
    """
    Tracking Id of the chunk_group to update.
    """


class UpdateOrganizationReqPayload(BaseModel):
    name: Optional[str] = None
    """
    The new name of the organization. If not provided, the name will not be updated.
    """
    partner_configuration: Optional[Any] = None
    """
    New details for the partnership configuration. If not provided, the partnership configuration will not be updated.
    """


class UpdateTopicReqPayload(BaseModel):
    name: str
    """
    The new name of the topic. A name is not generated from this field, it is used as-is.
    """
    topic_id: UUID
    """
    The id of the topic to target.
    """


class UpdateUserOrgRoleReqPayload(BaseModel):
    role: int
    """
    Either 0 (user), 1 (admin), or 2 (owner). If not provided, the current role will be used. The auth'ed user must have a role greater than or equal to the role being assigned.
    """
    user_id: Optional[UUID] = None
    """
    The id of the user to update, if not provided, the auth'ed user will be updated. If provided, the role of the auth'ed user or api key must be an admin (1) or owner (2) of the organization.
    """


class UploadFileReqPayload(BaseModel):
    base64_file: str
    """
    Base64 encoded file. This is the standard base64url encoding.
    """
    create_chunks: Optional[bool] = None
    """
    Create chunks is a boolean which determines whether or not to create chunks from the file. If false, you can manually chunk the file and send the chunks to the create_chunk endpoint with the file_id to associate chunks with the file. Meant mostly for advanced users.
    """
    description: Optional[str] = None
    """
    Description is an optional convience field so you do not have to remember what the file contains or is about. It will be included on the group resulting from the file which will hold its chunk.
    """
    file_name: str
    """
    Name of the file being uploaded, including the extension.
    """
    group_tracking_id: Optional[str] = None
    """
    Group tracking id is an optional field which allows you to specify the tracking id of the group that is created from the file. Chunks created will be created with the tracking id of `group_tracking_id|<index of chunk>`
    """
    link: Optional[str] = None
    """
    Link to the file. This can also be any string. This can be used to filter when searching for the file's resulting chunks. The link value will not affect embedding creation.
    """
    metadata: Optional[Any] = None
    """
    Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. Will be passed down to the file's chunks.
    """
    pdf2md_options: Optional[Pdf2MdOptions] = None
    rebalance_chunks: Optional[bool] = None
    """
    Rebalance chunks is an optional field which allows you to specify whether or not to rebalance the chunks created from the file. If not specified, the default true is used. If true, Trieve will evenly distribute remainder splits across chunks such that 66 splits with a `target_splits_per_chunk` of 20 will result in 3 chunks with 22 splits each.
    """
    split_avg: Optional[bool] = None
    """
    Split average will automatically split your file into multiple chunks and average all of the resulting vectors into a single output chunk. Default is false. Explicitly enabling this will cause each file to only produce a single chunk.
    """
    split_delimiters: Optional[list[str]] = None
    """
    Split delimiters is an optional field which allows you to specify the delimiters to use when splitting the file before chunking the text. If not specified, the default [.!?\n] are used to split into sentences. However, you may want to use spaces or other delimiters.
    """
    tag_set: Optional[list[str]] = None
    """
    Tag set is a comma separated list of tags which will be passed down to the chunks made from the file. Tags are used to filter chunks when searching. HNSW indices are created for each tag such that there is no performance loss when filtering on them.
    """
    target_splits_per_chunk: Annotated[Optional[int], Field(ge=0)] = None
    """
    Target splits per chunk. This is an optional field which allows you to specify the number of splits you want per chunk. If not specified, the default 20 is used. However, you may want to use a different number.
    """
    time_stamp: Optional[str] = None
    """
    Time stamp should be an ISO 8601 combined date and time without timezone. Time_stamp is used for time window filtering and recency-biasing search results. Will be passed down to the file's chunks.
    """


class UploadFileResponseBody(BaseModel):
    file_metadata: File


class UsageGraphPoint(BaseModel):
    requests: int
    time_stamp: str


class UserApiKey(BaseModel):
    api_key_hash: Optional[str] = None
    blake3_hash: Optional[str] = None
    created_at: datetime
    dataset_ids: Optional[list[Optional[str]]] = None
    expires_at: Optional[datetime] = None
    id: UUID
    name: str
    organization_ids: Optional[list[Optional[str]]] = None
    params: Optional[Any] = None
    role: int
    scopes: Optional[list[Optional[str]]] = None
    updated_at: datetime
    user_id: UUID


class UserOrganization(BaseModel):
    created_at: datetime
    id: UUID
    organization_id: UUID
    role: int
    updated_at: datetime
    user_id: UUID


class V1RecommendChunksResponseBody(RootModel[list[ChunkMetadataWithScore]]):
    root: list[ChunkMetadataWithScore]


class WorkerEvent(BaseModel):
    created_at: str
    dataset_id: UUID
    event_data: str
    event_type: str
    id: UUID


class CTRDataRequestBody(BaseModel):
    clicked_chunk_id: Optional[UUID] = None
    """
    The ID of chunk that was clicked
    """
    clicked_chunk_tracking_id: Optional[str] = None
    """
    The tracking ID of the chunk that was clicked
    """
    ctr_type: CTRType
    metadata: Optional[Any] = None
    """
    Any metadata you want to include with the event i.e. action, user_id, etc.
    """
    position: int
    """
    The position of the clicked chunk
    """
    request_id: UUID
    """
    The request id for the CTR data
    """


class CTRRecommendationsWithoutClicksResponse(BaseModel):
    recommendations: list[RecommendationsWithoutClicksCTRResponse]


class CTRSearchQueryWithoutClicksResponse(BaseModel):
    queries: list[SearchQueriesWithoutClicksCTRResponse]


class ChatMessageProxy(BaseModel):
    content: str
    role: RoleProxy


class ClusterAnalyticsFilter(BaseModel):
    date_range: Optional[DateRange] = None


class CrawlOptions(BaseModel):
    """
    Options for setting up the crawl which will populate the dataset.
    """

    allow_external_links: Optional[bool] = None
    """
    Option for allowing the crawl to follow links to external websites.
    """
    body_remove_strings: Optional[list[str]] = None
    """
    Text strings to remove from body when creating chunks for each page
    """
    boost_titles: Optional[bool] = None
    """
    Boost titles such that keyword matches in titles are prioritized in search results. Strongly recommended to leave this on. Defaults to true.
    """
    exclude_paths: Optional[list[str]] = None
    """
    URL Patterns to exclude from the crawl
    """
    exclude_tags: Optional[list[str]] = None
    """
    Specify the HTML tags, classes and ids to exclude from the response.
    """
    heading_remove_strings: Optional[list[str]] = None
    """
    Text strings to remove from headings when creating chunks for each page
    """
    ignore_sitemap: Optional[bool] = None
    """
    Ignore the website sitemap when crawling, defaults to true.
    """
    include_paths: Optional[list[str]] = None
    """
    URL Patterns to include in the crawl
    """
    include_tags: Optional[list[str]] = None
    """
    Specify the HTML tags, classes and ids to include in the response.
    """
    interval: Optional[CrawlInterval] = None
    limit: Optional[int] = None
    """
    How many pages to crawl, defaults to 1000
    """
    scrape_options: Optional[ScrapeOptions] = None
    site_url: Optional[str] = None
    """
    The URL to crawl
    """
    webhook_metadata: Optional[Any] = None
    """
    Metadata to send back with the webhook call for each successful page scrape
    """
    webhook_url: Optional[str] = None
    """
    Host to call back on the webhook for each successful page scrape
    """


class CrawlRequest(BaseModel):
    attempt_number: int
    crawl_options: CrawlOptions
    crawl_type: CrawlType
    created_at: datetime
    dataset_id: UUID
    id: UUID
    interval: str
    next_crawl_at: datetime
    scrape_id: UUID
    status: CrawlStatus
    url: str


class CreateBatchChunkGroupReqPayload(
    RootModel[list[CreateSingleChunkGroupReqPayload]]
):
    root: Annotated[
        list[CreateSingleChunkGroupReqPayload],
        Field(
            examples=[
                [
                    {
                        "description": (
                            "All versions and colorways of the oversized t-shirt"
                        ),
                        "metadata": {"foo": "bar"},
                        "name": "Versions of Oversized T-Shirt",
                        "tag_set": ["tshirt", "oversized", "clothing"],
                        "tracking_id": "SNOVERSIZEDTSHIRT",
                        "upsert_by_tracking_id": False,
                    },
                    {
                        "description": (
                            "All versions and colorways of the slim-fit t-shirt"
                        ),
                        "metadata": {"foo": "bar"},
                        "name": "Versions of Slim-Fit T-Shirt",
                        "tag_set": ["tshirt", "slim", "clothing"],
                        "tracking_id": "SNSLIMFITTSHIRT",
                        "upsert_by_tracking_id": False,
                    },
                ]
            ]
        ),
    ]


class CreateChunkGroupReqPayloadEnum(
    RootModel[Union[CreateSingleChunkGroupReqPayload, CreateBatchChunkGroupReqPayload]]
):
    root: Union[CreateSingleChunkGroupReqPayload, CreateBatchChunkGroupReqPayload]


class CreateCrawlReqPayload(BaseModel):
    crawl_options: CrawlOptions


class CreatePresignedUrlForCsvJsonResponseBody(BaseModel):
    file_metadata: File
    presigned_put_url: str
    """
    Signed URL to upload the file to.
    """


class DatasetAndUsage(BaseModel):
    dataset: DatasetDTO
    dataset_usage: DatasetUsageCount


class EventAnalyticsFilter(BaseModel):
    """
    Filter to apply to the events when querying for them
    """

    date_range: Optional[DateRange] = None
    event_type: Optional[EventTypesFilter] = None
    is_conversion: Optional[bool] = None
    """
    Filter by conversions
    """
    metadata_filter: Optional[str] = None
    """
    Filter by metadata path i.e. path.attribute = \"value\"
    """
    user_id: Optional[str] = None
    """
    Filter by user ID
    """


class EventReturn(BaseModel):
    event_types: list[str]
    events: list[WorkerEvent]
    page_count: int


class EventTypes1(BaseModel):
    event_name: str
    """
    The name of the event
    """
    event_type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]
    items: list[str]
    """
    The items that were viewed
    """
    metadata: Optional[Any] = None
    """
    Any other metadata associated with the event
    """
    request: Optional[RequestInfo] = None
    user_id: Optional[str] = None
    """
    The user id of the user who viewed the items
    """


class EventTypes2(BaseModel):
    event_name: str
    """
    The name of the event
    """
    event_type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]
    is_conversion: Optional[bool] = None
    """
    Whether the event is a conversion event
    """
    items: list[str]
    """
    The items that were added to the cart
    """
    metadata: Optional[Any] = None
    """
    Any other metadata associated with the event
    """
    request: Optional[RequestInfo] = None
    user_id: Optional[str] = None
    """
    The user id of the user who added the items to the cart
    """


class EventTypes3(BaseModel):
    clicked_items: ChunkWithPosition
    event_name: str
    """
    The name of the event
    """
    event_type: Literal["2#-datamodel-code-generator-#-object-#-special-#"]
    is_conversion: Optional[bool] = None
    """
    Whether the event is a conversion event
    """
    request: Optional[RequestInfo] = None
    user_id: Optional[str] = None
    """
    The user id of the user who clicked the items
    """


class EventTypes4(BaseModel):
    currency: Optional[str] = None
    """
    The currency of the purchase
    """
    event_name: str
    """
    The name of the event
    """
    event_type: Literal["3#-datamodel-code-generator-#-object-#-special-#"]
    is_conversion: Optional[bool] = None
    """
    Whether the event is a conversion event
    """
    items: list[str]
    """
    The items that were purchased
    """
    request: Optional[RequestInfo] = None
    user_id: Optional[str] = None
    """
    The user id of the user who purchased the items
    """
    value: Optional[float] = None
    """
    The value of the purchase
    """


class EventTypes5(BaseModel):
    event_name: str
    """
    The name of the event
    """
    event_type: Literal["4#-datamodel-code-generator-#-object-#-special-#"]
    is_conversion: Optional[bool] = None
    """
    Whether the event is a conversion event
    """
    items: dict[str, str]
    """
    The filter items that were clicked in a hashmap ie. {filter_name: filter_value} where filter_name is filter_type::field_name
    """
    request: Optional[RequestInfo] = None
    user_id: Optional[str] = None
    """
    The user id of the user who clicked the items
    """


class EventTypes6(BaseModel):
    event_type: Literal["5#-datamodel-code-generator-#-object-#-special-#"]
    latency: Optional[float] = None
    """
    Latency of the search
    """
    query: str
    """
    The search query
    """
    query_rating: Optional[SearchQueryRating] = None
    request_params: Optional[Any] = None
    """
    The request params of the search
    """
    results: Optional[list] = None
    """
    The results of the search
    """
    search_type: Optional[ClickhouseSearchTypes] = None
    top_score: Optional[float] = None
    """
    The top score of the search
    """
    user_id: Optional[str] = None
    """
    The user id of the user who made the search
    """


class EventTypes7(BaseModel):
    detected_hallucinations: Optional[list[str]] = None
    """
    The detected hallucinations of the RAG event
    """
    event_type: Literal["6#-datamodel-code-generator-#-object-#-special-#"]
    hallucination_score: Optional[float] = None
    """
    The hallucination score of the RAG event
    """
    llm_response: Optional[str] = None
    """
    The response from the LLM
    """
    query_rating: Optional[SearchQueryRating] = None
    rag_type: Optional[ClickhouseRagTypes] = None
    results: Optional[list] = None
    """
    The results of the RAG event
    """
    search_id: Optional[UUID] = None
    """
    The search id to associate the RAG event with a search
    """
    user_id: Optional[str] = None
    """
    The user id of the user who made the RAG event
    """
    user_message: str
    """
    The user message
    """


class EventTypes(
    RootModel[
        Union[
            EventTypes1,
            EventTypes2,
            EventTypes3,
            EventTypes4,
            EventTypes5,
            EventTypes6,
            EventTypes7,
            EventTypes8,
        ]
    ]
):
    root: Annotated[
        Union[
            EventTypes1,
            EventTypes2,
            EventTypes3,
            EventTypes4,
            EventTypes5,
            EventTypes6,
            EventTypes7,
            EventTypes8,
        ],
        Field(discriminator="event_type"),
    ]


class GenerateOffChunksReqPayload(BaseModel):
    audio_input: Optional[str] = None
    """
    Audio input to be used in the chat. This will be used to generate the audio tokens for the model. The default is None.
    """
    chunk_ids: list[UUID]
    """
    The ids of the chunks to be retrieved and injected into the context window for RAG.
    """
    context_options: Optional[ContextOptions] = None
    frequency_penalty: Optional[float] = None
    """
    Frequency penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. Default is 0.7.
    """
    highlight_results: Optional[bool] = None
    """
    Set highlight_results to false for a slight latency improvement (1-10ms). If not specified, this defaults to true. This will add `<mark><b>` tags to the chunk_html of the chunks to highlight matching splits.
    """
    image_config: Optional[ImageConfig] = None
    image_urls: Optional[list[str]] = None
    """
    Image URLs to be used in the chat. These will be used to generate the image tokens for the model. The default is None.
    """
    max_tokens: Annotated[Optional[int], Field(ge=0)] = None
    """
    The maximum number of tokens to generate in the chat completion. Default is None.
    """
    presence_penalty: Optional[float] = None
    """
    Presence penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Default is 0.7.
    """
    prev_messages: list[ChatMessageProxy]
    """
    The previous messages to be placed into the chat history. There must be at least one previous message.
    """
    prompt: Optional[str] = None
    """
    Prompt will be used to tell the model what to generate in the next message in the chat. The default is 'Respond to the previous instruction and include the doc numbers that you used in square brackets at the end of the sentences that you used the docs for:'. You can also specify an empty string to leave the final message alone such that your user's final message can be used as the prompt. See docs.trieve.ai or contact us for more information.
    """
    stop_tokens: Optional[list[str]] = None
    """
    Stop tokens are up to 4 sequences where the API will stop generating further tokens. Default is None.
    """
    stream_response: Optional[bool] = None
    """
    Whether or not to stream the response. If this is set to true or not included, the response will be a stream. If this is set to false, the response will be a normal JSON response. Default is true.
    """
    temperature: Optional[float] = None
    """
    What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Default is 0.5.
    """
    user_id: Optional[str] = None
    """
    User ID is the id of the user who is making the request. This is used to track user interactions with the RAG results.
    """


class GeoInfo(BaseModel):
    """
    Location that you want to use as the center of the search.
    """

    lat: GeoTypes
    lon: GeoTypes


class GeoInfoWithBias(BaseModel):
    """
    Location bias lets you rank your results by distance from a location. If not specified, this has no effect. Bias allows you to determine how much of an effect the location of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
    """

    bias: float
    """
    Bias lets you specify how much of an effect the location of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
    """
    location: GeoInfo


class GetAllTagsResponse(BaseModel):
    tags: list[TagsWithCount]
    """
    List of tags with the number of chunks in the dataset with that tag.
    """
    total: int
    """
    Total number of unique tags in the dataset.
    """


class GetEventsRequestBody(BaseModel):
    filter: Optional[EventAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page of results to return
    """


class GetTopDatasetsRequestBody(BaseModel):
    date_range: Optional[DateRange] = None
    type: TopDatasetsRequestTypes


class HighlightOptions(BaseModel):
    """
    Highlight Options lets you specify different methods to highlight the chunks in the result set. If not specified, this defaults to the score of the chunks.
    """

    highlight_delimiters: Optional[list[str]] = None
    """
    Set highlight_delimiters to a list of strings to use as delimiters for highlighting. If not specified, this defaults to ["?", ",", ".", "!"]. These are the characters that will be used to split the chunk_html into splits for highlighting. These are the characters that will be used to split the chunk_html into splits for highlighting.
    """
    highlight_max_length: Annotated[Optional[int], Field(ge=0)] = None
    """
    Set highlight_max_length to control the maximum number of tokens (typically whitespace separated strings, but sometimes also word stems) which can be present within a single highlight. If not specified, this defaults to 8. This is useful to shorten large splits which may have low scores due to length compared to the query. Set to something very large like 100 to highlight entire splits.
    """
    highlight_max_num: Annotated[Optional[int], Field(ge=0)] = None
    """
    Set highlight_max_num to control the maximum number of highlights per chunk. If not specified, this defaults to 3. It may be less than 3 if no snippets score above the highlight_threshold.
    """
    highlight_results: Optional[bool] = None
    """
    Set highlight_results to false for a slight latency improvement (1-10ms). If not specified, this defaults to true. This will add `<mark><b>` tags to the chunk_html of the chunks to highlight matching splits and return the highlights on each scored chunk in the response.
    """
    highlight_strategy: Optional[HighlightStrategy] = None
    highlight_threshold: Optional[float] = None
    """
    Set highlight_threshold to a lower or higher value to adjust the sensitivity of the highlights applied to the chunk html. If not specified, this defaults to 0.8. The range is 0.0 to 1.0.
    """
    highlight_window: Annotated[Optional[int], Field(ge=0)] = None
    """
    Set highlight_window to a number to control the amount of words that are returned around the matched phrases. If not specified, this defaults to 0. This is useful for when you want to show more context around the matched words. When specified, window/2 whitespace separated words are added before and after each highlight in the response's highlights array. If an extended highlight overlaps with another highlight, the overlapping words are only included once. This parameter can be overriden to respect the highlight_max_length param.
    """
    post_tag: Optional[str] = None
    """
    Custom html tag which should appear after highlights. If not specified, this defaults to '</mark></b>'.
    """
    pre_tag: Optional[str] = None
    """
    Custom html tag which should appear before highlights. If not specified, this defaults to '<mark><b>'.
    """


class LatencyGraphResponse(BaseModel):
    latency_points: list[SearchLatencyGraph]


class LocationBoundingBox(BaseModel):
    bottom_right: GeoInfo
    top_left: GeoInfo


class LocationPolygon(BaseModel):
    exterior: list[GeoInfo]
    interior: Optional[list[list[GeoInfo]]] = None


class LocationRadius(BaseModel):
    center: GeoInfo
    radius: float


class Metadata(BaseModel):
    articleSection: Optional[str] = None
    articleTag: Optional[str] = None
    dcDate: Optional[str] = None
    dcDateCreated: Optional[str] = None
    dcDescription: Optional[str] = None
    dcSubject: Optional[str] = None
    dcTermsAudience: Optional[str] = None
    dcTermsCreated: Optional[str] = None
    dcTermsKeywords: Optional[str] = None
    dcTermsSubject: Optional[str] = None
    dcTermsType: Optional[str] = None
    dcType: Optional[str] = None
    description: Optional[str] = None
    error: Optional[str] = None
    keywords: Optional[str] = None
    language: Optional[str] = None
    modifiedTime: Optional[str] = None
    ogAudio: Optional[str] = None
    ogDescription: Optional[str] = None
    ogDeterminer: Optional[str] = None
    ogImage: Optional[str] = None
    ogLocale: Optional[str] = None
    ogLocaleAlternate: Optional[list[str]] = None
    ogSiteName: Optional[str] = None
    ogTitle: Optional[str] = None
    ogUrl: Optional[str] = None
    ogVideo: Optional[str] = None
    publishedTime: Optional[str] = None
    robots: Optional[str] = None
    site_map: Optional[Sitemap] = None
    sourceURL: Optional[str] = None
    statusCode: Annotated[Optional[int], Field(ge=0)] = None
    title: Optional[str] = None


class MultiQuery(BaseModel):
    """
    MultiQuery allows you to construct a dense vector from multiple queries with a weighted sum. This is useful for when you want to emphasize certain features of the query. This only works with Semantic Search and is not compatible with cross encoder re-ranking or highlights.
    """

    query: SearchModalities
    weight: float
    """
    Float value which is applies as a multiplier to the query vector when summing.
    """


class OrganizationWithSubAndPlan(BaseModel):
    organization: Organization
    plan: Optional[StripePlan] = None
    subscription: Optional[StripeSubscription] = None


class QdrantChunkMetadata(BaseModel):
    chunk_html: Optional[str] = None
    dataset_id: UUID
    group_ids: Optional[list[UUID]] = None
    image_urls: Optional[list[str]] = None
    link: Optional[str] = None
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    num_value: Optional[float] = None
    qdrant_point_id: UUID
    tag_set: Optional[list[str]] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    weight: float


class QueryCountResponse(BaseModel):
    total_queries: list[SearchTypeCount]


class QueryTypes(RootModel[Union[SearchModalities, list[MultiQuery]]]):
    root: Union[SearchModalities, list[MultiQuery]]
    """
    Query is the search query. This can be any string. The query will be used to create an embedding vector and/or SPLADE vector which will be used to find the result set.  You can either provide one query, or multiple with weights. Multi-query only works with Semantic Search and is not compatible with cross encoder re-ranking or highlights.
    """


class RAGAnalyticsFilter(BaseModel):
    date_range: Optional[DateRange] = None
    rag_type: Optional[RagTypes] = None


class RAGUsageGraphResponse(BaseModel):
    usage_points: list[UsageGraphPoint]


class RagQueryEvent(BaseModel):
    created_at: str
    dataset_id: UUID
    detected_hallucinations: list[str]
    hallucination_score: float
    id: UUID
    llm_response: str
    query_rating: Optional[SearchQueryRating] = None
    rag_type: ClickhouseRagTypes
    results: list
    search_id: UUID
    top_score: float
    user_id: str
    user_message: str


class RagQueryResponse(BaseModel):
    queries: list[RagQueryEvent]


class Range(BaseModel):
    gt: Optional[RangeCondition] = None
    gte: Optional[RangeCondition] = None
    lt: Optional[RangeCondition] = None
    lte: Optional[RangeCondition] = None


class RecommendationAnalyticsFilter(BaseModel):
    date_range: Optional[DateRange] = None
    recommendation_type: Optional[RecommendationType] = None


class RecommendationAnalyticsResponse(
    RootModel[Union[RecommendationsEventResponse, RecommendationEvent]]
):
    root: Union[RecommendationsEventResponse, RecommendationEvent]


class ScoringOptions(BaseModel):
    """
    Scoring options provides ways to modify the sparse or dense vector created for the query in order to change how potential matches are scored. If not specified, this defaults to no modifications.
    """

    fulltext_boost: Optional[FullTextBoost] = None
    semantic_boost: Optional[SemanticBoost] = None


class SearchAnalyticsFilter(BaseModel):
    date_range: Optional[DateRange] = None
    search_method: Optional[SearchMethod] = None
    search_type: Optional[SearchType] = None


class SearchClusterResponse(BaseModel):
    clusters: list[SearchClusterTopics]


class SearchQueryEvent(BaseModel):
    created_at: str
    dataset_id: UUID
    id: UUID
    latency: float
    query: str
    query_rating: Optional[SearchQueryRating] = None
    request_params: Any
    results: list
    search_type: ClickhouseSearchTypes
    top_score: float
    user_id: str


class SearchQueryResponse(BaseModel):
    queries: list[SearchQueryEvent]


class SearchUsageGraphResponse(BaseModel):
    usage_points: list[UsageGraphPoint]


class SlimChunkMetadata(BaseModel):
    created_at: datetime
    dataset_id: UUID
    id: UUID
    image_urls: Optional[list[Optional[str]]] = None
    link: Optional[str] = None
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    num_value: Optional[float] = None
    tag_set: Optional[str] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    updated_at: datetime
    weight: float


class SlimChunkMetadataWithArrayTagSet(BaseModel):
    created_at: datetime
    dataset_id: UUID
    id: UUID
    image_urls: Optional[list[Optional[str]]] = None
    link: Optional[str] = None
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    num_value: Optional[float] = None
    tag_set: Optional[list[str]] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    updated_at: datetime
    weight: float


class SlimUser(BaseModel):
    created_at: datetime
    email: str
    id: UUID
    name: Optional[str] = None
    orgs: list[Organization]
    user_orgs: list[UserOrganization]


class SortByField(BaseModel):
    direction: Optional[SortOrder] = None
    field: str
    """
    Field to sort by. This has to be a numeric field with a Qdrant `Range` index on it. i.e. num_value and timestamp
    """
    prefetch_amount: Annotated[Optional[int], Field(ge=0)] = None
    """
    How many results to pull in before the sort
    """


class ToolFunctionParameter(BaseModel):
    """
    Function parameter for a LLM tool call
    """

    description: str
    """
    The description of the tag.
    """
    name: str
    """
    Name of the parameter.
    """
    parameter_type: ToolFunctionParameterType


class TypoOptions(BaseModel):
    """
    Typo Options lets you specify different methods to correct typos in the query. If not specified, typos will not be corrected.
    """

    correct_typos: Optional[bool] = None
    """
    Set correct_typos to true to correct typos in the query. If not specified, this defaults to false.
    """
    disable_on_word: Optional[list[str]] = None
    """
    Words that should not be corrected. If not specified, this defaults to an empty list.
    """
    one_typo_word_range: Optional[TypoRange] = None
    prioritize_domain_specifc_words: Optional[bool] = None
    """
    Auto-require non-english words present in the dataset to exist in each results chunk_html text. If not specified, this defaults to true.
    """
    two_typo_word_range: Optional[TypoRange] = None


class UpdateChunkReqPayload(BaseModel):
    chunk_html: Optional[str] = None
    """
    HTML content of the chunk you want to update. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content. If no chunk_html is provided, the existing chunk_html will be used.
    """
    chunk_id: Optional[UUID] = None
    """
    Id of the chunk you want to update. You can provide either the chunk_id or the tracking_id. If both are provided, the chunk_id will be used.
    """
    convert_html_to_text: Optional[bool] = None
    """
    Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
    """
    fulltext_boost: Optional[FullTextBoost] = None
    group_ids: Optional[list[UUID]] = None
    """
    Group ids are the ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
    """
    group_tracking_ids: Optional[list[str]] = None
    """
    Group tracking_ids are the tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
    """
    image_urls: Optional[list[str]] = None
    """
    Image urls are a list of urls to images that are associated with the chunk. This is useful for when you want to associate images with a chunk. If no image_urls are provided, the existing image_urls will be used.
    """
    link: Optional[str] = None
    """
    Link of the chunk you want to update. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation. If no link is provided, the existing link will be used.
    """
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    """
    The metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. If no metadata is provided, the existing metadata will be used.
    """
    num_value: Optional[float] = None
    """
    Num value is an arbitrary numerical value that can be used to filter chunks. This is useful for when you want to filter chunks by numerical value. If no num_value is provided, the existing num_value will be used.
    """
    semantic_boost: Optional[SemanticBoost] = None
    tag_set: Optional[list[str]] = None
    """
    Tag set is a list of tags. This can be used to filter chunks by tag. Unlike with metadata filtering, HNSW indices will exist for each tag such that there is not a performance hit for filtering on them. If no tag_set is provided, the existing tag_set will be used.
    """
    time_stamp: Optional[str] = None
    """
    Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results. If no time_stamp is provided, the existing time_stamp will be used.
    """
    tracking_id: Optional[str] = None
    """
    Tracking_id of the chunk you want to update. This is required to match an existing chunk.
    """
    weight: Optional[float] = None
    """
    Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset. If no weight is provided, the existing weight will be used.
    """


class UpdateCrawlReqPayload(BaseModel):
    crawl_id: UUID
    """
    Crawl ID to update
    """
    crawl_options: CrawlOptions


class CTRAnalytics1(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics2(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics3(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["2#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics4(BaseModel):
    filter: Optional[RecommendationAnalyticsFilter] = None
    type: Literal["3#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics5(BaseModel):
    filter: Optional[RecommendationAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["4#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics6(BaseModel):
    filter: Optional[RecommendationAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["5#-datamodel-code-generator-#-object-#-special-#"]


class CTRAnalytics(
    RootModel[
        Union[
            CTRAnalytics1,
            CTRAnalytics2,
            CTRAnalytics3,
            CTRAnalytics4,
            CTRAnalytics5,
            CTRAnalytics6,
        ]
    ]
):
    root: Annotated[
        Union[
            CTRAnalytics1,
            CTRAnalytics2,
            CTRAnalytics3,
            CTRAnalytics4,
            CTRAnalytics5,
            CTRAnalytics6,
        ],
        Field(discriminator="type"),
    ]


class ChunkMetadata(BaseModel):
    chunk_html: Optional[str] = None
    """
    HTML content of the chunk, can also be an arbitrary string which is not HTML
    """
    created_at: datetime
    """
    Timestamp of the creation of the chunk
    """
    dataset_id: UUID
    """
    ID of the dataset which the chunk belongs to
    """
    id: UUID
    """
    Unique identifier of the chunk, auto-generated uuid created by Trieve
    """
    image_urls: Optional[list[Optional[str]]] = None
    """
    Image URLs of the chunk, can be any list of strings. Used for image search and RAG.
    """
    link: Optional[str] = None
    """
    Link to the chunk, should be a URL
    """
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    """
    Metadata of the chunk, can be any JSON object
    """
    num_value: Optional[float] = None
    """
    Numeric value of the chunk, can be any float. Can represent the most relevant numeric value of the chunk, such as a price, quantity in stock, rating, etc.
    """
    tag_set: Optional[list[Optional[str]]] = None
    """
    Tag set of the chunk, can be any list of strings. Used for tag-filtered searches.
    """
    time_stamp: Optional[datetime] = None
    """
    Timestamp of the chunk, can be any timestamp. Specified by the user.
    """
    tracking_id: Optional[str] = None
    """
    Tracking ID of the chunk, can be any string, determined by the user. Tracking ID's are unique identifiers for chunks within a dataset. They are designed to match the unique identifier of the chunk in the user's system.
    """
    updated_at: datetime
    """
    Timestamp of the last update of the chunk
    """
    weight: float
    """
    Weight of the chunk, can be any float. Used as a multiplier on a chunk's relevance score for ranking purposes.
    """


class ChunkMetadataStringTagSet(BaseModel):
    chunk_html: Optional[str] = None
    created_at: datetime
    dataset_id: UUID
    id: UUID
    image_urls: Optional[list[Optional[str]]] = None
    link: Optional[str] = None
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    num_value: Optional[float] = None
    tag_set: Optional[str] = None
    time_stamp: Optional[datetime] = None
    tracking_id: Optional[str] = None
    updated_at: datetime
    weight: float


class ChunkMetadataTypes(
    RootModel[Union[SlimChunkMetadata, ChunkMetadataStringTagSet, ContentChunkMetadata]]
):
    root: Union[SlimChunkMetadata, ChunkMetadataStringTagSet, ContentChunkMetadata]


class ChunkMetadataWithPosition(BaseModel):
    chunk: ChunkMetadata
    position: int


class ChunkReqPayload(BaseModel):
    """
    Request payload for creating a new chunk
    """

    chunk_html: Optional[str] = None
    """
    HTML content of the chunk. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content.
    """
    convert_html_to_text: Optional[bool] = None
    """
    Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
    """
    fulltext_boost: Optional[FullTextBoost] = None
    group_ids: Optional[list[UUID]] = None
    """
    Group ids are the Trieve generated ids of the groups that the chunk should be placed into. This is useful for when you want to create a chunk and add it to a group or multiple groups in one request. Groups with these Trieve generated ids must be created first, it cannot be arbitrarily created through this route.
    """
    group_tracking_ids: Optional[list[str]] = None
    """
    Group tracking_ids are the user-assigned tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to create a chunk and add it to a group or multiple groups in one request. If a group with the tracking_id does not exist, it will be created.
    """
    high_priority: Optional[bool] = None
    """
    High Priority allows you to place this chunk into a priority queue with its own ingestion workers. Can only be used by users with a Custom Pro plan.
    """
    image_urls: Optional[list[str]] = None
    """
    Image urls are a list of urls to images that are associated with the chunk. This is useful for when you want to associate images with a chunk.
    """
    link: Optional[str] = None
    """
    Link to the chunk. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation.
    """
    location: Optional[GeoInfo] = None
    metadata: Optional[Any] = None
    """
    Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata.
    """
    num_value: Optional[float] = None
    """
    Num value is an arbitrary numerical value that can be used to filter chunks. This is useful for when you want to filter chunks by numerical value. There is no performance hit for filtering on num_value.
    """
    semantic_boost: Optional[SemanticBoost] = None
    semantic_content: Optional[str] = None
    """
    If semantic_content is present, it will be used for creating semantic embeddings instead of the innerText `chunk_html`. `chunk_html` will still be the only thing stored and always used for fulltext functionality. `chunk_html` must still be present for the chunk to be created properly.
    """
    split_avg: Optional[bool] = None
    """
    Split avg is a boolean which tells the server to split the text in the chunk_html into smaller chunks and average their resulting vectors. This is useful for when you want to create a chunk from a large piece of text and want to split it into smaller chunks to create a more fuzzy average dense vector. The sparse vector will be generated normally with no averaging. By default this is false.
    """
    tag_set: Optional[list[str]] = None
    """
    Tag set is a list of tags. This can be used to filter chunks by tag. Unlike with metadata filtering, HNSW indices will exist for each tag such that there is not a performance hit for filtering on them.
    """
    time_stamp: Optional[str] = None
    """
    Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results.
    """
    tracking_id: Optional[str] = None
    """
    Tracking_id is a string which can be used to identify a chunk. This is useful for when you are coordinating with an external system and want to use the tracking_id to identify the chunk.
    """
    upsert_by_tracking_id: Optional[bool] = None
    """
    Upsert when a chunk with the same tracking_id exists. By default this is false, and chunks will be ignored if another with the same tracking_id exists. If this is true, the chunk will be updated if a chunk with the same tracking_id exists.
    """
    weight: Optional[float] = None
    """
    Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset.
    """


class ChunkReturnTypes(RootModel[Union[ChunkMetadata, ChunkMetadataStringTagSet]]):
    root: Union[ChunkMetadata, ChunkMetadataStringTagSet]


class ClusterAnalytics1(BaseModel):
    filter: Optional[ClusterAnalyticsFilter] = None
    type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]


class ClusterAnalytics(RootModel[Union[ClusterAnalytics1, ClusterAnalytics2]]):
    root: Annotated[
        Union[ClusterAnalytics1, ClusterAnalytics2], Field(discriminator="type")
    ]


class ClusterAnalyticsResponse(
    RootModel[Union[SearchClusterResponse, SearchQueryResponse]]
):
    root: Union[SearchClusterResponse, SearchQueryResponse]


class CreateBatchChunkReqPayload(RootModel[list[ChunkReqPayload]]):
    root: Annotated[
        list[ChunkReqPayload],
        Field(
            examples=[
                [
                    {
                        "chunk_html": "<p>Some HTML content</p>",
                        "group_ids": ["d290f1ee-6c54-4b01-90e6-d701748f0851"],
                        "group_tracking_ids": ["group_tracking_id"],
                        "image_urls": [
                            "https://example.com/red",
                            "https://example.com/blue",
                        ],
                        "link": "https://example.com",
                        "location": {"lat": -34, "lon": 151},
                        "metadata": {"key1": "value1", "key2": "value2"},
                        "tag_set": ["tag1", "tag2"],
                        "time_stamp": "2021-01-01 00:00:00.000",
                        "tracking_id": "tracking_id",
                        "upsert_by_tracking_id": True,
                    },
                    {
                        "chunk_html": "<p>Some more HTML content</p>",
                        "group_ids": ["d290f1ee-6c54-4b01-90e6-d701748f0851"],
                        "group_tracking_ids": ["group_tracking_id"],
                        "image_urls": [],
                        "link": "https://explain.com",
                        "location": {"lat": -34, "lon": 151},
                        "metadata": {"key1": "value1", "key2": "value2"},
                        "tag_set": ["tag3", "tag4"],
                        "time_stamp": "2021-01-01 00:00:00.000",
                        "tracking_id": "tracking_id",
                        "upsert_by_tracking_id": True,
                        "weight": 0.5,
                    },
                ]
            ]
        ),
    ]


class CreateSingleChunkReqPayload(RootModel[ChunkReqPayload]):
    root: ChunkReqPayload


class Document(BaseModel):
    extract: Optional[str] = None
    html: Optional[str] = None
    links: Optional[list[str]] = None
    markdown: Optional[str] = None
    metadata: Metadata
    rawHtml: Optional[str] = None
    screenshot: Optional[str] = None


class FieldCondition(BaseModel):
    """
    FieldCondition is a JSON object which can be used to filter chunks by a field. This is useful for when you want to filter chunks by arbitrary metadata. To access fields inside of the metadata that you provide with the card, prefix the field name with `metadata.`.
    """

    boolean: Optional[bool] = None
    """
    Boolean is a true false value for a field. This only works for boolean fields. You can specify this if you want values to be true or false.
    """
    date_range: Optional[DateRange] = None
    field: str
    """
    Field is the name of the field to filter on. Commonly used fields are `timestamp`, `link`, `tag_set`, `location`, `num_value`, `group_ids`, and `group_tracking_ids`. The field value will be used to check for an exact substring match on the metadata values for each existing chunk. This is useful for when you want to filter chunks by arbitrary metadata. To access fields inside of the metadata that you provide with the card, prefix the field name with `metadata.`.
    """
    geo_bounding_box: Optional[LocationBoundingBox] = None
    geo_polygon: Optional[LocationPolygon] = None
    geo_radius: Optional[LocationRadius] = None
    match_all: Optional[list[MatchCondition]] = None
    """
    Match all lets you pass in an array of values that will return results if all of the items match. The match value will be used to check for an exact substring match on the metadata values for each existing chunk. If both match_all and match_any are provided, the match_any condition will be used.
    """
    match_any: Optional[list[MatchCondition]] = None
    """
    Match any lets you pass in an array of values that will return results if any of the items match. The match value will be used to check for an exact substring match on the metadata values for each existing chunk. If both match_all and match_any are provided, the match_any condition will be used.
    """
    range: Optional[Range] = None


class GetChunksInGroupsResponseBody(BaseModel):
    chunks: list[ChunkMetadata]
    group: ChunkGroupAndFileId
    total_pages: Annotated[int, Field(ge=0)]


class GroupsBookmarkQueryResult(BaseModel):
    chunks: list[ChunkMetadataStringTagSet]
    group: ChunkGroupAndFileId
    total_pages: Annotated[int, Field(ge=0)]


class NewChunkMetadataTypes(
    RootModel[
        Union[SlimChunkMetadataWithArrayTagSet, ChunkMetadata, ContentChunkMetadata]
    ]
):
    root: Union[SlimChunkMetadataWithArrayTagSet, ChunkMetadata, ContentChunkMetadata]


class QdrantSortBy(RootModel[Union[SortByField, SortBySearchType]]):
    root: Union[SortByField, SortBySearchType]
    """
    Sort by lets you specify a method to sort the results by. If not specified, this defaults to the score of the chunks. If specified, this can be any key in the chunk metadata. This key must be a numeric value within the payload.
    """


class RAGAnalytics1(BaseModel):
    filter: Optional[RAGAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    sort_by: Optional[RAGSortBy] = None
    sort_order: Optional[SortOrder] = None
    type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]


class RAGAnalytics2(BaseModel):
    filter: Optional[RAGAnalyticsFilter] = None
    type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]


class RAGAnalytics3(BaseModel):
    filter: Optional[RAGAnalyticsFilter] = None
    granularity: Optional[Granularity] = None
    type: Literal["2#-datamodel-code-generator-#-object-#-special-#"]


class RAGAnalytics(
    RootModel[Union[RAGAnalytics1, RAGAnalytics2, RAGAnalytics3, RAGAnalytics4]]
):
    root: Annotated[
        Union[RAGAnalytics1, RAGAnalytics2, RAGAnalytics3, RAGAnalytics4],
        Field(discriminator="type"),
    ]


class RAGAnalyticsResponse(
    RootModel[
        Union[RagQueryResponse, RAGUsageResponse, RAGUsageGraphResponse, RagQueryEvent]
    ]
):
    root: Union[
        RagQueryResponse, RAGUsageResponse, RAGUsageGraphResponse, RagQueryEvent
    ]


class RecommendationAnalytics1(BaseModel):
    filter: Optional[RecommendationAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    threshold: Optional[float] = None
    type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]


class RecommendationAnalytics2(BaseModel):
    filter: Optional[RecommendationAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    sort_by: Optional[SearchSortBy] = None
    sort_order: Optional[SortOrder] = None
    type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]


class RecommendationAnalytics(
    RootModel[
        Union[
            RecommendationAnalytics1, RecommendationAnalytics2, RecommendationAnalytics3
        ]
    ]
):
    root: Annotated[
        Union[
            RecommendationAnalytics1, RecommendationAnalytics2, RecommendationAnalytics3
        ],
        Field(discriminator="type"),
    ]


class RecommendationsWithClicksCTRResponse(BaseModel):
    clicked_chunk: ChunkMetadataWithPosition
    created_at: str
    negative_ids: Optional[list[str]] = None
    negative_tracking_ids: Optional[list[str]] = None
    positive_ids: Optional[list[str]] = None
    positive_tracking_ids: Optional[list[str]] = None
    request_id: str
    results: list


class ScoreChunk(BaseModel):
    chunk: NewChunkMetadataTypes
    highlights: Optional[list[str]] = None
    score: float


class ScoreChunkDTO(BaseModel):
    highlights: Optional[list[str]] = None
    metadata: list[ChunkMetadataTypes]
    score: float


class ScrollChunksResponseBody(BaseModel):
    chunks: list[ChunkMetadata]


class SearchAnalytics1(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    granularity: Optional[Granularity] = None
    type: Literal["0#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics2(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    granularity: Optional[Granularity] = None
    type: Literal["1#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics3(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    type: Literal["2#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics4(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["3#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics5(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    threshold: Optional[float] = None
    type: Literal["4#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics6(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    type: Literal["5#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics7(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    sort_by: Optional[SearchSortBy] = None
    sort_order: Optional[SortOrder] = None
    type: Literal["6#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics8(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    type: Literal["7#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics10(BaseModel):
    filter: Optional[SearchAnalyticsFilter] = None
    type: Literal["9#-datamodel-code-generator-#-object-#-special-#"]


class SearchAnalytics(
    RootModel[
        Union[
            SearchAnalytics1,
            SearchAnalytics2,
            SearchAnalytics3,
            SearchAnalytics4,
            SearchAnalytics5,
            SearchAnalytics6,
            SearchAnalytics7,
            SearchAnalytics8,
            SearchAnalytics9,
            SearchAnalytics10,
        ]
    ]
):
    root: Annotated[
        Union[
            SearchAnalytics1,
            SearchAnalytics2,
            SearchAnalytics3,
            SearchAnalytics4,
            SearchAnalytics5,
            SearchAnalytics6,
            SearchAnalytics7,
            SearchAnalytics8,
            SearchAnalytics9,
            SearchAnalytics10,
        ],
        Field(discriminator="type"),
    ]


class SearchAnalyticsResponse(
    RootModel[
        Union[
            LatencyGraphResponse,
            SearchUsageGraphResponse,
            DatasetAnalytics,
            HeadQueryResponse,
            SearchQueryResponse,
            QueryCountResponse,
            SearchQueryEvent,
            PopularFiltersResponse,
        ]
    ]
):
    root: Union[
        LatencyGraphResponse,
        SearchUsageGraphResponse,
        DatasetAnalytics,
        HeadQueryResponse,
        SearchQueryResponse,
        QueryCountResponse,
        SearchQueryEvent,
        PopularFiltersResponse,
    ]


class SearchChunkQueryResponseBody(BaseModel):
    corrected_query: Optional[str] = None
    score_chunks: list[ScoreChunkDTO]
    total_chunk_pages: int


class SearchOverGroupsResults(BaseModel):
    chunks: list[ScoreChunk]
    file_id: Optional[UUID] = None
    group: ChunkGroup


class SearchQueriesWithClicksCTRResponse(BaseModel):
    clicked_chunk: ChunkMetadataWithPosition
    created_at: str
    query: str
    request_id: str
    results: list


class SearchResponseBody(BaseModel):
    chunks: list[ScoreChunk]
    corrected_query: Optional[str] = None
    id: UUID
    total_pages: int


class SearchResponseTypes(
    RootModel[Union[SearchResponseBody, SearchChunkQueryResponseBody]]
):
    root: Union[SearchResponseBody, SearchChunkQueryResponseBody]


class SearchWithinGroupResponseBody(BaseModel):
    chunks: list[ScoreChunk]
    corrected_query: Optional[str] = None
    id: UUID
    total_pages: int


class SearchWithinGroupResults(BaseModel):
    bookmarks: list[ScoreChunkDTO]
    corrected_query: Optional[str] = None
    group: ChunkGroupAndFileId
    total_pages: int


class SingleQueuedChunkResponse(BaseModel):
    chunk_metadata: ChunkMetadata


class SortOptions(BaseModel):
    """
    Sort Options lets you specify different methods to rerank the chunks in the result set. If not specified, this defaults to the score of the chunks.
    """

    location_bias: Optional[GeoInfoWithBias] = None
    mmr: Optional[MmrOptions] = None
    recency_bias: Optional[float] = None
    """
    Recency Bias lets you determine how much of an effect the recency of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
    """
    sort_by: Optional[QdrantSortBy] = None
    tag_weights: Optional[dict[str, float]] = None
    """
    Tag weights is a JSON object which can be used to boost the ranking of chunks with certain tags. This is useful for when you want to be able to bias towards chunks with a certain tag on the fly. The keys are the tag names and the values are the weights.
    """
    use_weights: Optional[bool] = None
    """
    Set use_weights to true to use the weights of the chunks in the result set in order to sort them. If not specified, this defaults to true.
    """


class ToolFunction(BaseModel):
    """
    Function for a LLM tool call
    """

    description: str
    """
    Description of the function.
    """
    name: str
    """
    Name of the function.
    """
    parameters: list[ToolFunctionParameter]
    """
    Parameters of the function.
    """


class UploadHtmlPageReqPayload(BaseModel):
    data: Document
    metadata: Any
    scrapeId: UUID


class BatchQueuedChunkResponse(BaseModel):
    chunk_metadata: list[ChunkMetadata]


class CTRRecommendationsWithClicksResponse(BaseModel):
    recommendations: list[RecommendationsWithClicksCTRResponse]


class CTRSearchQueryWithClicksResponse(BaseModel):
    queries: list[SearchQueriesWithClicksCTRResponse]


class ConditionType(RootModel[Union[FieldCondition, HasChunkIDCondition]]):
    root: Union[FieldCondition, HasChunkIDCondition]
    """
    Filters can be constructed using either fields on the chunk objects, ids or tracking ids of chunks, and finally ids or tracking ids of groups.
    """


class CreateChunkReqPayloadEnum(
    RootModel[Union[CreateSingleChunkReqPayload, CreateBatchChunkReqPayload]]
):
    root: Union[CreateSingleChunkReqPayload, CreateBatchChunkReqPayload]


class GetChunksInGroupResponse(
    RootModel[Union[GetChunksInGroupsResponseBody, GroupsBookmarkQueryResult]]
):
    root: Union[GetChunksInGroupsResponseBody, GroupsBookmarkQueryResult]


class GetToolFunctionParamsReqPayload(BaseModel):
    """
    Request payload for getting the parameters of a tool function
    """

    audio_input: Optional[str] = None
    """
    The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
    """
    image_url: Optional[str] = None
    """
    Image URL to attach to the message to generate the parameters for the tool function.
    """
    model: Optional[str] = None
    """
    Model name to use for the completion. If not specified, this defaults to the dataset's model.
    """
    tool_function: ToolFunction
    user_message_text: Optional[str] = None
    """
    Text of the user's message to the assistant which will be used to generate the parameters for the tool function.
    """


class GroupScoreChunk(BaseModel):
    file_id: Optional[UUID] = None
    group_created_at: datetime
    group_dataset_id: UUID
    group_description: Optional[str] = None
    group_id: UUID
    group_metadata: Optional[Any] = None
    group_name: Optional[str] = None
    group_tag_set: Optional[list[Optional[str]]] = None
    group_tracking_id: Optional[str] = None
    group_updated_at: datetime
    metadata: list[ScoreChunkDTO]


class RecommendChunksResponseBody(BaseModel):
    chunks: list[ScoreChunk]
    id: UUID


class RecommendGroupsResponseBody(BaseModel):
    id: UUID
    results: list[SearchOverGroupsResults]


class RecommendResponseTypes(
    RootModel[Union[RecommendChunksResponseBody, V1RecommendChunksResponseBody]]
):
    root: Union[RecommendChunksResponseBody, V1RecommendChunksResponseBody]


class ReturnQueuedChunk(
    RootModel[Union[SingleQueuedChunkResponse, BatchQueuedChunkResponse]]
):
    root: Union[SingleQueuedChunkResponse, BatchQueuedChunkResponse]


class SearchGroupResponseTypes(
    RootModel[Union[SearchWithinGroupResponseBody, SearchWithinGroupResults]]
):
    root: Union[SearchWithinGroupResponseBody, SearchWithinGroupResults]


class SearchOverGroupsResponseBody(BaseModel):
    corrected_query: Optional[str] = None
    id: UUID
    results: list[SearchOverGroupsResults]
    total_pages: int


class SearchResultType(RootModel[Union[ScoreChunkDTO, GroupScoreChunk]]):
    root: Union[ScoreChunkDTO, GroupScoreChunk]


class CTRAnalyticsResponse(
    RootModel[
        Union[
            SearchCTRMetrics,
            CTRSearchQueryWithoutClicksResponse,
            CTRSearchQueryWithClicksResponse,
            RecommendationCTRMetrics,
            CTRRecommendationsWithoutClicksResponse,
            CTRRecommendationsWithClicksResponse,
        ]
    ]
):
    root: Union[
        SearchCTRMetrics,
        CTRSearchQueryWithoutClicksResponse,
        CTRSearchQueryWithClicksResponse,
        RecommendationCTRMetrics,
        CTRRecommendationsWithoutClicksResponse,
        CTRRecommendationsWithClicksResponse,
    ]


class ChunkFilter(BaseModel):
    """
    ChunkFilter is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata.
    """

    must: Optional[list[ConditionType]] = None
    """
    All of these field conditions have to match for the chunk to be included in the result set.
    """
    must_not: Optional[list[ConditionType]] = None
    """
    None of these field conditions can match for the chunk to be included in the result set.
    """
    should: Optional[list[ConditionType]] = None
    """
    Only one of these field conditions has to match for the chunk to be included in the result set.
    """


class CountChunksReqPayload(BaseModel):
    filters: Optional[ChunkFilter] = None
    limit: Annotated[Optional[int], Field(ge=0)] = None
    """
    Set limit to restrict the maximum number of chunks to count. This is useful for when you want to reduce the latency of the count operation. By default the limit will be the number of chunks in the dataset.
    """
    query: QueryTypes
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_type: CountSearchMethod
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """


class CreateMessageReqPayload(BaseModel):
    audio_input: Optional[str] = None
    """
    The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
    """
    concat_user_messages_query: Optional[bool] = None
    """
    If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
    """
    context_options: Optional[ContextOptions] = None
    filters: Optional[ChunkFilter] = None
    highlight_options: Optional[HighlightOptions] = None
    image_urls: Optional[list[str]] = None
    """
    The URL of the image(s) to attach to the message.
    """
    llm_options: Optional[LLMOptions] = None
    new_message_content: Optional[str] = None
    """
    The content of the user message to attach to the topic and then generate an assistant message in response to.
    """
    no_result_message: Optional[str] = None
    """
    No result message for when there are no chunks found above the score threshold.
    """
    only_include_docs_used: Optional[bool] = None
    """
    Only include docs used in the completion. If not specified, this defaults to false.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_query: Optional[str] = None
    """
    Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
    """
    search_type: Optional[SearchMethod] = None
    sort_options: Optional[SortOptions] = None
    topic_id: UUID
    """
    The ID of the topic to attach the message to.
    """
    use_group_search: Optional[bool] = None
    """
    If use_group_search is set to true, the search will be conducted using the `search_over_groups` api. If not specified, this defaults to false.
    """
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
    """


class DeprecatedSearchOverGroupsResponseBody(BaseModel):
    corrected_query: Optional[str] = None
    group_chunks: list[GroupScoreChunk]
    total_chunk_pages: int


class EditMessageReqPayload(BaseModel):
    audio_input: Optional[str] = None
    """
    The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
    """
    concat_user_messages_query: Optional[bool] = None
    """
    If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
    """
    context_options: Optional[ContextOptions] = None
    filters: Optional[ChunkFilter] = None
    highlight_options: Optional[HighlightOptions] = None
    image_urls: Optional[list[str]] = None
    """
    The URL of the image(s) to attach to the message.
    """
    llm_options: Optional[LLMOptions] = None
    message_sort_order: int
    """
    The sort order of the message to edit.
    """
    new_message_content: Optional[str] = None
    """
    The new content of the message to replace the old content with.
    """
    no_result_message: Optional[str] = None
    """
    No result message for when there are no chunks found above the score threshold.
    """
    only_include_docs_used: Optional[bool] = None
    """
    Only include docs used in the completion. If not specified, this defaults to false.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_query: Optional[str] = None
    """
    Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
    """
    search_type: Optional[SearchMethod] = None
    sort_options: Optional[SortOptions] = None
    topic_id: UUID
    """
    The id of the topic to edit the message at the given sort order for.
    """
    use_group_search: Optional[bool] = None
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
    """


class PublicPageSearchOptions(BaseModel):
    content_only: Optional[bool] = None
    """
    Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    filters: Optional[ChunkFilter] = None
    get_total_pages: Optional[bool] = None
    """
    Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
    """
    page: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page of chunks to fetch. Page is 1-indexed.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold for cosine distance metric. For Manhattan Distance, Euclidean Distance, and Dot Product, it will filter out scores above the threshold distance. This threshold applies before weight and bias modifications. If not specified, this defaults to no threshold. A threshold of 0 will default to no threshold.
    """
    scoring_options: Optional[ScoringOptions] = None
    search_type: Optional[SearchMethod] = None
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    sort_options: Optional[SortOptions] = None
    typo_options: Optional[TypoOptions] = None
    use_autocomplete: Optional[bool] = None
    """
    Enables autocomplete on the search modal.
    """
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """
    user_id: Optional[str] = None
    """
    User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
    """


class RecommendChunksRequest(BaseModel):
    filters: Optional[ChunkFilter] = None
    limit: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of chunks to return. This is the number of chunks which will be returned in the response. The default is 10.
    """
    negative_chunk_ids: Optional[list[UUID]] = None
    """
    The ids of the chunks to be used as negative examples for the recommendation. The chunks in this array will be used to filter out similar chunks.
    """
    negative_tracking_ids: Optional[list[str]] = None
    """
    The tracking_ids of the chunks to be used as negative examples for the recommendation. The chunks in this array will be used to filter out similar chunks.
    """
    positive_chunk_ids: Optional[list[UUID]] = None
    """
    The ids of the chunks to be used as positive examples for the recommendation. The chunks in this array will be used to find similar chunks.
    """
    positive_tracking_ids: Optional[list[str]] = None
    """
    The tracking_ids of the chunks to be used as positive examples for the recommendation. The chunks in this array will be used to find similar chunks.
    """
    recommend_type: Optional[RecommendType] = None
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
    """
    strategy: Optional[RecommendationStrategy] = None
    user_id: Optional[str] = None
    """
    User ID is the id of the user who is making the request. This is used to track user interactions with the recommendation results.
    """


class RecommendGroupsReqPayload(BaseModel):
    filters: Optional[ChunkFilter] = None
    group_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of chunks to fetch for each group. This is the number of chunks which will be returned in the response for each group. The default is 3. If this is set to a large number, we recommend setting slim_chunks to true to avoid returning the content and chunk_html of the chunks so as to reduce latency due to content download and serialization.
    """
    limit: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of groups to return. This is the number of groups which will be returned in the response. The default is 10.
    """
    negative_group_ids: Optional[list[UUID]] = None
    """
    The ids of the groups to be used as negative examples for the recommendation. The groups in this array will be used to filter out similar groups.
    """
    negative_group_tracking_ids: Optional[list[str]] = None
    """
    The ids of the groups to be used as negative examples for the recommendation. The groups in this array will be used to filter out similar groups.
    """
    positive_group_ids: Optional[list[UUID]] = None
    """
    The ids of the groups to be used as positive examples for the recommendation. The groups in this array will be used to find similar groups.
    """
    positive_group_tracking_ids: Optional[list[str]] = None
    """
    The ids of the groups to be used as positive examples for the recommendation. The groups in this array will be used to find similar groups.
    """
    recommend_type: Optional[RecommendType] = None
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
    """
    strategy: Optional[RecommendationStrategy] = None
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the rrecommendation results.
    """


class RecommendGroupsResponse(
    RootModel[Union[RecommendGroupsResponseBody, GroupScoreChunk]]
):
    root: Union[RecommendGroupsResponseBody, GroupScoreChunk]


class RegenerateMessageReqPayload(BaseModel):
    concat_user_messages_query: Optional[bool] = None
    """
    If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
    """
    context_options: Optional[ContextOptions] = None
    filters: Optional[ChunkFilter] = None
    highlight_options: Optional[HighlightOptions] = None
    llm_options: Optional[LLMOptions] = None
    no_result_message: Optional[str] = None
    """
    No result message for when there are no chunks found above the score threshold.
    """
    only_include_docs_used: Optional[bool] = None
    """
    Only include docs used in the completion. If not specified, this defaults to false.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_query: Optional[str] = None
    """
    Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
    """
    search_type: Optional[SearchMethod] = None
    sort_options: Optional[SortOptions] = None
    topic_id: UUID
    """
    The id of the topic to regenerate the last message for.
    """
    use_group_search: Optional[bool] = None
    """
    If use_group_search is set to true, the search will be conducted using the `search_over_groups` api. If not specified, this defaults to false.
    """
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
    """


class ScrollChunksReqPayload(BaseModel):
    filters: Optional[ChunkFilter] = None
    offset_chunk_id: Optional[UUID] = None
    """
    Offset chunk id is the id of the chunk to start the page from. If not specified, this defaults to the first chunk in the dataset sorted by id ascending.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    sort_by: Optional[SortByField] = None


class SearchChunksReqPayload(BaseModel):
    content_only: Optional[bool] = None
    """
    Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    filters: Optional[ChunkFilter] = None
    get_total_pages: Optional[bool] = None
    """
    Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
    """
    highlight_options: Optional[HighlightOptions] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page of chunks to fetch. Page is 1-indexed.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    query: QueryTypes
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold for cosine distance metric. For Manhattan Distance, Euclidean Distance, and Dot Product, it will filter out scores above the threshold distance. This threshold applies before weight and bias modifications. If not specified, this defaults to no threshold. A threshold of 0 will default to no threshold.
    """
    scoring_options: Optional[ScoringOptions] = None
    search_type: SearchMethod
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    sort_options: Optional[SortOptions] = None
    typo_options: Optional[TypoOptions] = None
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """
    user_id: Optional[str] = None
    """
    User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
    """


class SearchOverGroupsReqPayload(BaseModel):
    filters: Optional[ChunkFilter] = None
    get_total_pages: Optional[bool] = None
    """
    Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
    """
    group_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Group_size is the number of chunks to fetch for each group. The default is 3. If a group has less than group_size chunks, all chunks will be returned. If this is set to a large number, we recommend setting slim_chunks to true to avoid returning the content and chunk_html of the chunks so as to lower the amount of time required for content download and serialization.
    """
    highlight_options: Optional[HighlightOptions] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page of group results to fetch. Page is 1-indexed.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of group results to fetch. The default is 10.
    """
    query: QueryTypes
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be
    preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_type: SearchMethod
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
    """
    sort_options: Optional[SortOptions] = None
    typo_options: Optional[TypoOptions] = None
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the search results.
    """


class SearchOverGroupsResponseTypes(
    RootModel[
        Union[SearchOverGroupsResponseBody, DeprecatedSearchOverGroupsResponseBody]
    ]
):
    root: Union[SearchOverGroupsResponseBody, DeprecatedSearchOverGroupsResponseBody]


class SearchWithinGroupReqPayload(BaseModel):
    content_only: Optional[bool] = None
    """
    Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    filters: Optional[ChunkFilter] = None
    get_total_pages: Optional[bool] = None
    """
    Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
    """
    group_id: Optional[UUID] = None
    """
    Group specifies the group to search within. Results will only consist of chunks which are bookmarks within the specified group.
    """
    group_tracking_id: Optional[str] = None
    """
    Group_tracking_id specifies the group to search within by tracking id. Results will only consist of chunks which are bookmarks within the specified group. If both group_id and group_tracking_id are provided, group_id will be used.
    """
    highlight_options: Optional[HighlightOptions] = None
    page: Annotated[Optional[int], Field(ge=0)] = None
    """
    The page of chunks to fetch. Page is 1-indexed.
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    The page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    query: QueryTypes
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    search_type: SearchMethod
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
    """
    sort_options: Optional[SortOptions] = None
    typo_options: Optional[TypoOptions] = None
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """
    user_id: Optional[str] = None
    """
    The user_id is the id of the user who is making the request. This is used to track user interactions with the search results.
    """


class SuggestedQueriesReqPayload(BaseModel):
    context: Optional[str] = None
    """
    Context is the context of the query. This can be any string under 15 words and 200 characters. The context will be used to generate the suggested queries. Defaults to None.
    """
    filters: Optional[ChunkFilter] = None
    query: Optional[str] = None
    """
    The query to base the generated suggested queries off of using RAG. A hybrid search for 10 chunks from your dataset using this query will be performed and the context of the chunks will be used to generate the suggested queries.
    """
    search_type: Optional[SearchMethod] = None
    suggestion_type: Optional[SuggestType] = None
    suggestions_to_create: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of suggested queries to create, defaults to 10
    """


class ApiKeyRequestParams(BaseModel):
    """
    The default parameters which will be forcibly used when the api key is given on a request. If not provided, the api key will not have default parameters.
    """

    filters: Optional[ChunkFilter] = None
    highlight_options: Optional[HighlightOptions] = None
    no_result_message: Optional[str] = None
    """
    Options for handling the response for the llm to return when no results are found
    """
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words will be removed. Queries that are entirely stop words will be preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold.
    """
    search_type: Optional[SearchMethod] = None
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks.
    """
    typo_options: Optional[TypoOptions] = None
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively.
    """


class AutocompleteReqPayload(BaseModel):
    content_only: Optional[bool] = None
    """
    Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    extend_results: Optional[bool] = None
    """
    If specified to true, this will extend the search results to include non-exact prefix matches of the same search_type such that a full page_size of results are returned. Default is false.
    """
    filters: Optional[ChunkFilter] = None
    highlight_options: Optional[HighlightOptions] = None
    page_size: Annotated[Optional[int], Field(ge=0)] = None
    """
    Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
    """
    query: SearchModalities
    remove_stop_words: Optional[bool] = None
    """
    If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
    """
    score_threshold: Optional[float] = None
    """
    Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
    """
    scoring_options: Optional[ScoringOptions] = None
    search_type: SearchMethod
    slim_chunks: Optional[bool] = None
    """
    Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
    """
    sort_options: Optional[SortOptions] = None
    typo_options: Optional[TypoOptions] = None
    use_quote_negated_terms: Optional[bool] = None
    """
    If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
    """
    user_id: Optional[str] = None
    """
    User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
    """


class BulkDeleteChunkPayload(BaseModel):
    filter: ChunkFilter


class CreateApiKeyReqPayload(BaseModel):
    dataset_ids: Optional[list[UUID]] = None
    """
    The dataset ids which the api key will have access to. If not provided or empty, the api key will have access to all datasets in the dataset.
    """
    default_params: Optional[ApiKeyRequestParams] = None
    expires_at: Optional[str] = None
    """
    The expiration date of the api key. If not provided, the api key will not expire. This should be provided in UTC time.
    """
    name: str
    """
    The name which will be assigned to the new api key.
    """
    role: int
    """
    The role which will be assigned to the new api key. Either 0 (read), 1 (Admin) or 2 (Owner). The auth'ed user must have a role greater than or equal to the role being assigned.
    """
    scopes: Optional[list[str]] = None
    """
    The routes which the api key will have access to. If not provided or empty, the api key will have access to all routes. Specify the routes as a list of strings. For example, ["GET /api/dataset", "POST /api/dataset"].
    """


class PublicPageParameters(BaseModel):
    allowSwitchingModes: Optional[bool] = None
    analytics: Optional[bool] = None
    apiKey: Optional[str] = None
    baseUrl: Optional[str] = None
    brandColor: Optional[str] = None
    brandFontFamily: Optional[str] = None
    brandLogoImgSrcUrl: Optional[str] = None
    brandName: Optional[str] = None
    buttonTriggers: Optional[list[ButtonTrigger]] = None
    chat: Optional[bool] = None
    creatorLinkedInUrl: Optional[str] = None
    creatorName: Optional[str] = None
    currencyPosition: Optional[str] = None
    datasetId: Optional[UUID] = None
    debounceMs: Optional[int] = None
    defaultAiQuestions: Optional[list[str]] = None
    defaultCurrency: Optional[str] = None
    defaultImageQuestion: Optional[str] = None
    defaultSearchMode: Optional[str] = None
    defaultSearchQueries: Optional[list[str]] = None
    floatingButtonPosition: Optional[str] = None
    floatingSearchIconPosition: Optional[str] = None
    followupQuestions: Optional[bool] = None
    forBrandName: Optional[str] = None
    headingPrefix: Optional[str] = None
    heroPattern: Optional[HeroPattern] = None
    hideDrawnText: Optional[bool] = None
    inline: Optional[bool] = None
    inlineHeader: Optional[str] = None
    isTestMode: Optional[bool] = None
    navLogoImgSrcUrl: Optional[str] = None
    numberOfSuggestions: Annotated[Optional[int], Field(ge=0)] = None
    openGraphMetadata: Optional[OpenGraphMetadata] = None
    openLinksInNewTab: Optional[bool] = None
    placeholder: Optional[str] = None
    problemLink: Optional[str] = None
    responsive: Optional[bool] = None
    searchOptions: Optional[PublicPageSearchOptions] = None
    showFloatingButton: Optional[bool] = None
    showFloatingInput: Optional[bool] = None
    showFloatingSearchIcon: Optional[bool] = None
    showResultHighlights: Optional[bool] = None
    singleProductOptions: Optional[SingleProductOptions] = None
    suggestedQueries: Optional[bool] = None
    tabMessages: Optional[list[PublicPageTabMessage]] = None
    tags: Optional[list[PublicPageTag]] = None
    theme: Optional[PublicPageTheme] = None
    type: Optional[str] = None
    useGroupSearch: Optional[bool] = None
    useLocal: Optional[bool] = None
    usePagefind: Optional[bool] = None
    videoLink: Optional[str] = None
    videoPosition: Optional[str] = None
    zIndex: Optional[int] = None


class PublicDatasetOptions(BaseModel):
    enabled: bool
    extra_params: Optional[PublicPageParameters] = None


class DatasetConfigurationDTO(BaseModel):
    """
    Lets you specify the configuration for a dataset
    """

    BM25_AVG_LEN: Optional[float] = None
    """
    The average length of the chunks in the index for BM25
    """
    BM25_B: Optional[float] = None
    """
    The BM25 B parameter
    """
    BM25_ENABLED: Optional[bool] = None
    """
    Whether to use BM25
    """
    BM25_K: Optional[float] = None
    """
    The BM25 K parameter
    """
    DISABLE_ANALYTICS: Optional[bool] = None
    """
    Whether to disable analytics
    """
    DISTANCE_METRIC: Optional[DistanceMetric] = None
    EMBEDDING_BASE_URL: Optional[str] = None
    """
    The base URL for the embedding API
    """
    EMBEDDING_MODEL_NAME: Optional[str] = None
    """
    The name of the embedding model to use
    """
    EMBEDDING_QUERY_PREFIX: Optional[str] = None
    """
    The prefix to use for the embedding query
    """
    EMBEDDING_SIZE: Annotated[Optional[int], Field(ge=0)] = None
    """
    The size of the embeddings
    """
    FREQUENCY_PENALTY: Optional[float] = None
    """
    The frequency penalty to use
    """
    FULLTEXT_ENABLED: Optional[bool] = None
    """
    Whether to use fulltext search
    """
    INDEXED_ONLY: Optional[bool] = None
    """
    Whether to only use indexed chunks
    """
    LLM_BASE_URL: Optional[str] = None
    """
    The base URL for the LLM API
    """
    LLM_DEFAULT_MODEL: Optional[str] = None
    """
    The default model to use for the LLM
    """
    LOCKED: Optional[bool] = None
    """
    Whether the dataset is locked to prevent changes or deletion
    """
    MAX_LIMIT: Annotated[Optional[int], Field(ge=0)] = None
    """
    The maximum limit for the number of chunks for counting
    """
    MAX_TOKENS: Annotated[Optional[int], Field(ge=0)] = None
    """
    The maximum number of tokens to use in LLM Response
    """
    MESSAGE_TO_QUERY_PROMPT: Optional[str] = None
    """
    The prompt to use for converting a message to a query
    """
    N_RETRIEVALS_TO_INCLUDE: Annotated[Optional[int], Field(ge=0)] = None
    """
    The number of retrievals to include with the RAG model
    """
    PAGEFIND_ENABLED: Optional[bool] = None
    """
    Whether to enable pagefind indexing
    """
    PRESENCE_PENALTY: Optional[float] = None
    """
    The presence penalty to use
    """
    PUBLIC_DATASET: Optional[PublicDatasetOptions] = None
    QDRANT_ONLY: Optional[bool] = None
    """
    Whether or not to insert chunks into Postgres
    """
    RAG_PROMPT: Optional[str] = None
    """
    The prompt to use for the RAG model
    """
    RERANKER_BASE_URL: Optional[str] = None
    """
    The base URL for the reranker API
    """
    RERANKER_MODEL_NAME: Optional[str] = None
    """
    The model name for the Reranker API
    """
    SEMANTIC_ENABLED: Optional[bool] = None
    """
    Whether to use semantic search
    """
    STOP_TOKENS: Optional[list[str]] = None
    """
    The stop tokens to use
    """
    SYSTEM_PROMPT: Optional[str] = None
    """
    The system prompt to use for the LLM
    """
    TEMPERATURE: Optional[float] = None
    """
    The temperature to use
    """
    USE_MESSAGE_TO_QUERY_PROMPT: Optional[bool] = None
    """
    Whether to use the message to query prompt
    """


class UpdateDatasetReqPayload(BaseModel):
    dataset_id: Optional[UUID] = None
    """
    The id of the dataset you want to update.
    """
    dataset_name: Optional[str] = None
    """
    The new name of the dataset. Must be unique within the organization. If not provided, the name will not be updated.
    """
    new_tracking_id: Optional[str] = None
    """
    Optional new tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. If not provided, the tracking ID will not be updated. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
    """
    server_configuration: Optional[DatasetConfigurationDTO] = None
    tracking_id: Optional[str] = None
    """
    The tracking ID of the dataset you want to update.
    """


class CreateBatchDataset(BaseModel):
    dataset_name: str
    """
    Name of the dataset.
    """
    server_configuration: Optional[DatasetConfigurationDTO] = None
    tracking_id: Optional[str] = None
    """
    Optional tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
    """


class CreateDatasetBatchReqPayload(BaseModel):
    datasets: list[CreateBatchDataset]
    """
    List of datasets to create
    """
    upsert: Optional[bool] = None
    """
    Upsert when a dataset with one of the specified tracking_ids already exists. By default this is false and specified datasets with a tracking_id that already exists in the org will not be ignored. If true, the existing dataset will be updated with the new dataset's details.
    """


class CreateDatasetReqPayload(BaseModel):
    dataset_name: str
    """
    Name of the dataset.
    """
    server_configuration: Optional[DatasetConfigurationDTO] = None
    tracking_id: Optional[str] = None
    """
    Optional tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
    """
